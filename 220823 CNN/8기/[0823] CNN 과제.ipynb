{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[0823] CNN 과제.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. 폴더 정리\n","\n","* 제공해드린 animals10.zip의 압축을 풀어 그 내용을 살펴보시고, 폴더 구조를 학습에 알맞도록 재구성해주세요\n","* 특히 각 클래스마다 약 30% 정도의 이미지를 test 폴더에 할당해주세요\n","* 중간중간 헷갈리다면 이것저것 확인하는 코드를 거쳐보세요 (ex. flat_test[:5]로 앞의 다섯값 확인)\n","* 궁금한 점이 있을 경우, 슬랙 질문 채널 활용을 적극 권장합니다."],"metadata":{"id":"d2ENRS4E9_xy"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"lZhIoG9SDka-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661956374708,"user_tz":-540,"elapsed":45317,"user":{"displayName":"조보경","userId":"18441903002245672979"}},"outputId":"ac932ff0-5517-4dc0-b2d9-c776f152888c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7tlWm3L9KoV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"07d09e4b-d03a-4084-bbb9-39bd8b5ee414","executionInfo":{"status":"ok","timestamp":1661952863142,"user_tz":-540,"elapsed":16926,"user":{"displayName":"조보경","userId":"18441903002245672979"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/[0823] CNN\n","^C\n"]}],"source":["### Guideline for convenience ###\n","# 압축 풀기\n","\n","%cd /content/drive/MyDrive/Colab Notebooks/[0823] CNN\n","!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/[0823] CNN/animals10.zip\"\n"]},{"cell_type":"code","source":["# 각 클래스별 파일 개수 확인 -> 변수로 해당 개수 저장\n","# Tip) 클래스가 10개이므로 각 클래스마다 똑같은 내용의 코드를 계속 써야할까요? 클래스 이름을 리스트로 저장해 for문을 돌리면서 코드를 재사용하는건 어떨까요?\n","import os\n","from glob import glob\n","import os\n","import shutil\n","#Label과 Label 수 계산\n","print(dir)\n","Labels= os.listdir('Animals-10')\n","Labels_n=len(Labels)\n","\n","#각 Label 별 데이터의 개수 저장\n","Nums=[0 for i in range(Labels_n)]\n","for num in range(Labels_n):\n","  file_list = glob(f'./Animals-10/{Labels[num]}/*')\n","  Nums[num]= len(file_list)\n","print(Nums)"],"metadata":{"id":"RPXh3srt-1Rx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661952919943,"user_tz":-540,"elapsed":37307,"user":{"displayName":"조보경","userId":"18441903002245672979"}},"outputId":"3850b261-4538-4123-bea6-4696618f25f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<built-in function dir>\n","[2112, 1969, 3098, 1866, 4863, 1446, 2623, 1820, 4821, 1862]\n"]}]},{"cell_type":"code","source":["# test에 넣을 이미지 개수 계산\n","test_n=[0 for i in range(len(Nums))]\n","for num in range(len(Nums)):\n","  test_n[num]=round(Nums[num]*0.3)\n","\n","print(test_n)"],"metadata":{"id":"9Jikw6Rp_BQI","executionInfo":{"status":"ok","timestamp":1661952954501,"user_tz":-540,"elapsed":412,"user":{"displayName":"조보경","userId":"18441903002245672979"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"23a6c886-c1c9-477d-934c-0bbe6b26d0e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[634, 591, 929, 560, 1459, 434, 787, 546, 1446, 559]\n"]}]},{"cell_type":"code","source":["# train, test 폴더 경로 선언 & 만들기\n","from torchvision import transforms, datasets\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","train_paths=[]\n","test_paths=[]\n","\n"],"metadata":{"id":"bb2XMrAe_Fl8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train, test 폴더로 이미지 split해서 알맞게 집어넣기\n","import random\n","\n","def split(img_list, test_count, train_path, test_path,label):\n","  # img_list : 이미지 경로 리스트\n","  # test_count : test에 할당할 이미지 개수\n","  # train_path : train 데이터 넣을 경로\n","  # test_path : test 데이터 넣을 경로\n","  \n","  # 랜덤으로 test_count만큼 이미지 img_list에서 고르기\n","  # test 담을 이미지 리스트 저장\n","  test_files=[]\n","  for i in random.sample(img_list, test_count):\n","    test_files.append(i)\n","\n","  # 위에서 고르지 않은 이미지들을 train 담을 이미지 리스트로 저장\n","  train_files = [x for x in img_list if x not in test_files]\n","\n","  # 고른 이미지를 train_path, test_path폴더에 폭사\n","  for k in train_files:\n","    shutil.copy(k, train_path)\n","  \n","  for c in test_files:\n","    shutil.copy(c, test_path)\n","\n"," \n","\n","\n","\n","\n","#label list를 이용하여, 각 라벨마다 test와 train 경로 만듦\n","for label_n in range(Labels_n):\n","  label=Labels[label_n]\n","  train_path=f'./train/{label}'\n","  test_path=f'./test/{label}'\n","  os.makedirs(train_path, exist_ok=True)\n","  os.makedirs(test_path, exist_ok=True)\n","  img_list=glob(f'./Animals-10/{label}/*')\n","  split(img_list , test_n[label_n],train_path,test_path,label) "],"metadata":{"id":"BaAXh57G_srE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. CNN 모델\n","수업 코드에 '모델 성능에 대한 고민!!' 부분을 참고해서 **test 이미지 기준 최소 80% 이상**의 모델이 나올 수 있도록 학습을 진행해주세요.\n","* 중간중간 헷갈리다면 이것저것 확인하는 코드를 거쳐보세요\n","* 90% 이상의 모델이 이상적이긴 합니다\n","* 궁금한 점이 있을 경우, 슬랙 질문 채널 활용을 적극 권장합니다."],"metadata":{"id":"UKa7LZ4RAXxA"}},{"cell_type":"markdown","source":["전반적으로 수업 코드와 비슷하게 짜면 되는데, 생각해봐야 할 것은\n","* 모든 이미지를 내가 정의하는 하나의 모델에 넣어야함\n","* 그말은 input 데이터의 차원이 항상 동일해야 된다는 말\n","* 그런데 과연 내가 가지고 있는 이미지들의 사이즈가 모두 같을까? - 대략 얼마정도 사이즈 가지고 있는지 코드로 확인해보면 더 좋음 (shape 확인)\n","* 이미지 사이즈를 통일시키기 위해서는 어떻게 해야할까? - transforms의 Resize, RandomCrop 써볼까?\n","* 동물 이미지에 적합한 Augmentation은 무엇이 있을까?"],"metadata":{"id":"31hFiKNBD48l"}},{"cell_type":"code","source":["# train, test 이미지를 위한 transforms function 정의\n","# 위에서 말한 포인트들 생각해보기 - 차원에 유의하자!\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import imshow\n","import torchvision.transforms as transforms\n","from torchvision.transforms.functional import pad\n","\n","'''\n","#shape 확인\n","#(169, 300, 3)\n","#(200, 300, 3)\n","#(194, 270, 3)\n","#(258, 300, 3)\n","#(300, 225, 3)\n","\n","img_list=img_list=glob(f'./test/butterfly/*')[:5]\n","for img in img_list:\n","  img_=Image.open(img)\n","  img=np.array(img_)\n","  print(img.shape)\n","  '''\n","#Tesor 이미지는 (C, H, W)\n","\n","\n","\n","transform_ = transforms.Compose([ \n","    transforms.CenterCrop(250),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","]) "],"metadata":{"id":"UM1CiMcdAfas","executionInfo":{"status":"ok","timestamp":1661956517774,"user_tz":-540,"elapsed":3,"user":{"displayName":"조보경","userId":"18441903002245672979"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# ImageFolder와 앞서 정의한 transforms function을 활용해 Dataset 객체 (train, test에 대해) 선언\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","train_data = torchvision.datasets.ImageFolder(\n","    root = '/content/drive/MyDrive/Colab Notebooks/[0823] CNN/train', # 바로 train 폴더 지정\n","    transform = transform_ # transform은 그냥 편의상 cifar에서 썼던거 그대로\n",")\n","test_data = torchvision.datasets.ImageFolder(\n","    root = '/content/drive/MyDrive/Colab Notebooks/[0823] CNN/test',\n","    transform = transform_\n",")\n","#print(train_data[0][0].shape)\n"],"metadata":{"id":"QAYc35vdAlHk","executionInfo":{"status":"ok","timestamp":1661956593917,"user_tz":-540,"elapsed":56012,"user":{"displayName":"조보경","userId":"18441903002245672979"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# train, test에 대해 DataLoader 정의\n","\n","trainloader= torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size = 32,      # 일반적으로 batch size = 16, 32\n","    shuffle=True,         # train dataloader는 epoch마다 데이터 다시 섞어서 batch 만들고 학습! - 학습 효율 up\n","    num_workers=2\n",")\n","\n","testloader = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size = 32,      # 일반적으로 batch size = 16, 32\n","    shuffle=False,        # test dataloader는 데이터 매번 섞을 이유가 없음 - 어차피 확인 용도\n","    num_workers=2\n",")\n","\n"],"metadata":{"id":"gHF4PaUQAvzJ","executionInfo":{"status":"ok","timestamp":1661957547468,"user_tz":-540,"elapsed":476,"user":{"displayName":"조보경","userId":"18441903002245672979"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["### Model 클래스 정의 - 차원에 유의하자!\n","# 10개의 클래스를 분류해야 하는 꽤나 복잡한 task - 모델 구조를 어느 정도로 복잡하게 짜볼까?\n","# 가장 마지막 Linear의 out_features는 얼마로 해야할까?\n","import torch.nn as nn\n","class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        \n","        ##### Layer 정의 #####\n","        self.layer = nn.Sequential(\n","            # 맨처음 RGB 채널 3개이므로 가장 처음 in_channels = 3\n","            # img의 가장 첫 차원이 batch_size 값은 계속해서 유지\n","            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),             # [batch_size,3,32,32] -> [batch_size,16,28,28] -> same with? - using 16 filters\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),            # [batch_size,16,28,28] -> [batch_size,32,24,24]\n","            nn.ReLU(),\n","            nn.Dropout(0.2), # 0.2 확률로 Dropout\n","            nn.MaxPool2d(kernel_size=2, stride=2),                                # [batch_size,32,24,24] -> [batch_size,32,12,12]\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2), # [batch_size,32,12,12] -> [batch_size,32,12,12] -> padding*2 주의!\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),            # [batch_size,32,12,12] -> [batch_size,32,10,10]\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.MaxPool2d(kernel_size=2, stride=2)                                 # [batch_size,32,10,10] -> [batch_size,32,5,5]\n","        )\n","        self.fc_layer = nn.Sequential(\n","            nn.Linear(32*5*5,100),                                                # [batch_size,32*5*5] -> [batch_size,100]\n","            nn.ReLU(),\n","            nn.Linear(100,10)\n","        )\n","\n","    def forward(self, x):\n","        # forward pass 과정\n","        out = self.layer(x)\n","        out = out.view(out.size(0),-1)  # FC layer에 들어가기전, flatten! - view 함수 활용\n","                                        # 가장 첫 차원인 batch_size는 유지하고 나머지 차원들을 하나로 합치기 - [batch_size,16,5,5] -> [batch_size,16*5*5]\n","        out = self.fc_layer(out)\n","        return out"],"metadata":{"id":"Kpvu7SJtAyUH","executionInfo":{"status":"ok","timestamp":1661957886464,"user_tz":-540,"elapsed":483,"user":{"displayName":"조보경","userId":"18441903002245672979"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EEZBy8bv8uPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Device 선언 (GPU 권장)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device\n","mymodel = MyModel().to(device)"],"metadata":{"id":"A99ALViSCbmI","executionInfo":{"status":"ok","timestamp":1661957668614,"user_tz":-540,"elapsed":458,"user":{"displayName":"조보경","userId":"18441903002245672979"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# torchsummary로 모델 차원 어떻게 나오는지 돌려보기\n","#!pip install torchsummary\n","from torchsummary import summary\n","\n","test_model = mymodel() # 모델 객체 선언\n","summary(test_model, (3,32,32), batch_size=32) # Recall) Tensor는 C, H, W 순서로 이미지 가짐"],"metadata":{"id":"K_AvhGgTCXO7","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"error","timestamp":1661957905768,"user_tz":-540,"elapsed":915,"user":{"displayName":"조보경","userId":"18441903002245672979"}},"outputId":"176499a2-47f6-42c3-9668-b7ba90e02b5e"},"execution_count":25,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-736db9716f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모델 객체 선언\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Recall) Tensor는 C, H, W 순서로 이미지 가짐\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"]}]},{"cell_type":"code","source":["# 모델 객체 선언"],"metadata":{"id":"FmZYSSBFCfOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss func, optimizer 정의\n","criterion = nn.CrossEntropyLoss().to(device) # criterion (loss func)도 device 위에서\n","optimizer = torch.optim.Adam(mymodel.parameters(), lr=0.001, weight_decay=0.0001) # 보통 Adam의 learning rate로 0.001 사용\n","                                                                                  # weight_decay = L2 Regularization의 lambda값 (가중치 제한 정도)"],"metadata":{"id":"CFk7o_fuCgc7","executionInfo":{"status":"ok","timestamp":1661956803100,"user_tz":-540,"elapsed":2,"user":{"displayName":"조보경","userId":"18441903002245672979"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# train 함수 정의\n","with torch.no_grad():\n","    for i, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        print(inputs.shape)  # batch_size개의 이미지\n","        print(targets.shape) # batch_size개의 클래스\n","\n","        outputs = mymodel(inputs)\n","        print(outputs.shape) # outputs는 32, 10 차원 (32개 data의 확률 10개씩)\n","        print(targets.shape) # targets는 32차원 (32개 data의 실제 클래스)\n","\n","        loss = criterion(outputs, targets)  # -> cross entropy 식에 넣을때 이런 형태로 넣으면됨 (outputs, targets의 차원을 맞출 필요가 없음)\n","        print(loss.item())\n","\n","        print(outputs.max(1)[1]) # 예측한 클래스\n","        print(targets) # 실제 클래스\n","        correct = (outputs.max(1)[1] == targets).sum().item() # 맞게 예측한 클래스 개수\n","        print(correct)\n","        break"],"metadata":{"id":"-ENGsLI3CksA","colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"status":"error","timestamp":1661956849204,"user_tz":-540,"elapsed":43998,"user":{"displayName":"조보경","userId":"18441903002245672979"}},"outputId":"590ab332-7c68-423c-8a2a-4c5dcfaa47e9"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 3, 250, 250])\n","torch.Size([32])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f8bc96d34313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size개의 클래스\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# outputs는 32, 10 차원 (32개 data의 확률 10개씩)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# targets는 32차원 (32개 data의 실제 클래스)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-38130a901954>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FC layer에 들어가기전, flatten! - view 함수 활용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         \u001b[0;31m# 가장 첫 차원인 batch_size는 유지하고 나머지 차원들을 하나로 합치기 - [batch_size,16,5,5] -> [batch_size,16*5*5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x111392 and 800x100)"]}]},{"cell_type":"code","source":["# test 함수 정의"],"metadata":{"id":"zxKTZ7oACnGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training"],"metadata":{"id":"Y2AB6X97Cx4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss, accuracy 추이 확인 with plt.plot"],"metadata":{"id":"ZwJHGOY9Czzh"},"execution_count":null,"outputs":[]}]}