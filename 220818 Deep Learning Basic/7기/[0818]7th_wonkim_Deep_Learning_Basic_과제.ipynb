{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[0818]7th_wonkim_Deep_Learning_Basic_과제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rjuQY9f2mdS"
      },
      "source": [
        "## 과제 1\n",
        "ReLu activation function과 derivative function을 구현해보세요\n",
        "- Hint : np.maximum 함수 사용하면 편리합니다\n",
        "- 다른 방법 사용하셔도 무방합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np "
      ],
      "metadata": {
        "id": "MmwAwhstTNkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puH0YVGI2uLz"
      },
      "source": [
        "import numpy as np \n",
        "def relu(x):\n",
        "  \n",
        "  x= np.maximum (0,x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def d_relu(x):\n",
        "  x= np.maximum (0,x)\n",
        "  if x >0 :\n",
        "    x=1 \n",
        "    return x\n",
        "  else :\n",
        "    x=0\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Esm4jmTVijro"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x0= torch.tensor([1,2,3,4,-1,-2,-3])\n",
        "d_relu(x0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "LnUaCpuzoBq9",
        "outputId": "6b72a121-a6e2-4bce-a150-4225b78a3fca"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-51b7ccdfa587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-5a64ed8e4fa2>\u001b[0m in \u001b[0;36md_relu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0md_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz8Hi0Rc2-yJ"
      },
      "source": [
        "## 과제 2\n",
        "Deep Learning Basic 코드 파일의 MLP implementation with Numpy library using MNIST dataset 코드 참고해서\n",
        "Three layer MLP 일 때의 backward_pass 함수를 완성해주세요.   \n",
        "- Hint : 코드 파일의 예시는 Two layer MLP\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def foward_pass(x, params):\n",
        "  \n",
        "  params[\"S1\"] = np.dot(params[\"W1\"], x) + params[\"b1\"]\n",
        "  params[\"A1\"] = sigmoid(params[\"S1\"])\n",
        "  params[\"S2\"] = np.dot(params[\"W2\"], params[\"A1\"]) + params[\"b2\"]\n",
        "  params[\"A2\"] = sigmoid(params[\"S2\"])\n",
        "  params[\"S3\"] = np.dot(params[\"W3\"], params[\"A2\"]) + params[\"b3\"]\n",
        "  params[\"A3\"] = softmax(params[S3])\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "OeRbza7HdFs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fusEy49j3uhs"
      },
      "source": [
        "def backward_pass(x, y_true, params):\n",
        "\n",
        "  dS3 = params[\"A3\"] - y_true\n",
        "  grads = {}\n",
        "\n",
        "  grads[\"dW3\"] =  np.dot(dS3, params[\"A2\"].T)/x.shape[1]\n",
        "  grads[\"db3\"] =  (1/x.shape[1])*np.sum(dS3, axis=1, keepdims=True)/x.shape[1]\n",
        "\n",
        "  dA2 = np.dot(params[\"W3\"].T, dS3)\n",
        "  dS2 = dA2 * d_sigmoid(params[\"S2\"])\n",
        "\n",
        "  grads[\"dW2\"] = np.dot(dS2, params[\"A1\"].T)/x.shape[1]\n",
        "  grads[\"db2\"] = (1/x.shape[1])*np.sum(dS2, axis=1, keepdims=True)/x.shape[1]\n",
        "\n",
        "  dA1= np.dot(params[\"W2\"].T , dS2)\n",
        "  dS1= dA1 * d_sigmoid(params[\"S1\"])\n",
        "\n",
        "\n",
        "  grads[\"dW1\"] = np.dot(dS1, x.T)/x.shape[1]\n",
        "  grads[\"db1\"] = np.sum(dS1, axis=1, keepdims=True)/x.shape[1]\n",
        "\n",
        "  return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twf-R8s-34zT"
      },
      "source": [
        "## 과제 3\n",
        "Deep Learning Basic 코드 파일의 MLP implementation with Pytorch library using MNIST dataset 코드 참고해서\n",
        "Three layer MLP를 구한후, 학습을 돌려 보세요\n",
        "\n",
        "hyperparameter는 다음과 같이 설정\n",
        "\n",
        "- epochs : 100\n",
        "- hiddensize : 128, 64 (two layer)\n",
        "- learning_rate : 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxJO249A3jhk"
      },
      "source": [
        "# Assignment 3 구현은 여기서 ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "pI_0FlEGXRVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 텐서로 변경\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "lQK4P0XQXSWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.MNIST(\n",
        "    root      = './.data/', \n",
        "    train     = True,\n",
        "    download  = True,\n",
        "    transform = transform\n",
        ")\n",
        "testset = datasets.MNIST(\n",
        "    root      = './.data/', \n",
        "    train     = False,\n",
        "    download  = True,\n",
        "    transform = transform\n",
        ")"
      ],
      "metadata": {
        "id": "15-R3T81XX61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 512\n",
        "# train set과 test set 각각에 대하여 DataLoader를 생성합니다.\n",
        "# shuffle=True 매개변수를 넣어 데이터를 섞어주세요.\n",
        "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader =  DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "TNFazrUPXcWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.layer1 = nn.Linear(784,128)\n",
        "        self.layer2 = nn.Linear(128,64)\n",
        "        self.layer3 = nn.Linear(64,10)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        out = self.layer1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "NzAFehIxY3nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq5_ZhzUZIK5",
        "outputId": "ce333e23-195e-46bd-955d-287060828017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (layer3): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters()) # 행렬들을 직접 살펴볼 수 있음\n",
        "                         # require_true 얘는 학습되는 애구나 알 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSrfl94EZIlu",
        "outputId": "3c03efac-9269-4835-f2e3-eeb1b64a6987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0110, -0.0344,  0.0251,  ..., -0.0067,  0.0095,  0.0262],\n",
              "         [-0.0177,  0.0293,  0.0322,  ...,  0.0029, -0.0178,  0.0119],\n",
              "         [ 0.0227,  0.0264, -0.0101,  ...,  0.0287,  0.0271,  0.0071],\n",
              "         ...,\n",
              "         [-0.0150, -0.0054,  0.0009,  ...,  0.0278,  0.0046,  0.0333],\n",
              "         [-0.0304,  0.0125, -0.0286,  ..., -0.0022,  0.0214,  0.0153],\n",
              "         [ 0.0077,  0.0133, -0.0136,  ...,  0.0145, -0.0044, -0.0185]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-2.4017e-02,  3.8905e-03, -1.7750e-02,  8.5210e-03,  1.1645e-02,\n",
              "          6.1743e-03,  9.5233e-03,  3.3894e-02,  2.8637e-02, -2.8677e-02,\n",
              "         -2.5669e-02,  1.4855e-02, -1.0258e-02, -1.3765e-02,  1.7460e-02,\n",
              "         -1.9524e-02, -2.9866e-02, -2.7430e-02, -2.7848e-02, -5.1663e-03,\n",
              "         -1.5489e-02, -1.8940e-02,  7.1803e-03,  4.2274e-03, -8.0835e-03,\n",
              "         -3.0267e-02, -2.5036e-02, -1.1842e-02, -3.0982e-02,  1.6853e-02,\n",
              "          6.6013e-03, -1.5906e-02, -2.3548e-02, -3.4961e-02, -7.1639e-03,\n",
              "         -1.5872e-05,  1.4947e-02, -1.1432e-02,  2.2511e-02, -9.6939e-03,\n",
              "          2.8196e-02,  3.3315e-02,  1.9533e-02, -3.3685e-02,  3.2025e-02,\n",
              "          8.0844e-03, -2.0819e-02,  1.2846e-03,  9.3149e-03, -2.7276e-02,\n",
              "         -1.8218e-02,  2.3828e-02, -1.6224e-02,  1.8997e-02, -1.7202e-02,\n",
              "          2.9704e-02,  2.4646e-02, -1.1533e-02,  3.5160e-04, -1.2300e-02,\n",
              "         -1.0667e-02,  2.1235e-03,  3.1362e-02,  3.2441e-02, -3.3724e-02,\n",
              "          3.2753e-02,  1.1075e-02,  2.2504e-02,  7.4715e-03,  2.4588e-02,\n",
              "          2.5762e-02, -4.4821e-03, -1.8405e-02, -2.1228e-02,  1.4302e-02,\n",
              "         -3.5328e-02,  6.9713e-03,  1.5032e-02,  2.2507e-02,  9.8124e-03,\n",
              "         -2.9509e-02,  4.2395e-03,  1.5897e-02, -1.8500e-02,  2.5646e-02,\n",
              "         -1.4680e-02, -2.8944e-02,  3.2762e-02,  1.0094e-02, -2.2042e-02,\n",
              "         -1.5754e-02,  2.8906e-02,  3.3699e-02,  2.9440e-02,  3.0173e-02,\n",
              "         -3.1203e-02, -2.8040e-02,  2.3160e-02, -2.8189e-02, -1.0238e-03,\n",
              "          6.7913e-03, -3.2409e-02,  1.5223e-02,  8.1156e-03, -1.0778e-02,\n",
              "          3.1936e-02, -9.1468e-05,  1.9568e-02,  2.8373e-02,  3.9609e-03,\n",
              "         -3.5092e-02, -1.3710e-02, -1.9524e-03,  4.2717e-03,  2.8293e-02,\n",
              "         -1.1494e-02, -1.1101e-02,  1.2487e-02,  2.8811e-02,  1.6703e-02,\n",
              "         -5.1881e-04,  2.1936e-02, -9.7732e-03,  3.3789e-02,  1.5703e-02,\n",
              "         -3.7204e-03,  3.5590e-02,  2.5491e-02], requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0732, -0.0352,  0.0226,  ..., -0.0866,  0.0368, -0.0158],\n",
              "         [ 0.0678, -0.0338, -0.0349,  ..., -0.0085,  0.0784,  0.0824],\n",
              "         [ 0.0496, -0.0367, -0.0098,  ...,  0.0665, -0.0770,  0.0553],\n",
              "         ...,\n",
              "         [ 0.0877,  0.0419, -0.0800,  ...,  0.0273, -0.0706,  0.0259],\n",
              "         [-0.0558,  0.0823,  0.0707,  ...,  0.0327, -0.0654, -0.0478],\n",
              "         [-0.0676,  0.0572,  0.0779,  ...,  0.0649,  0.0271, -0.0835]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.0124,  0.0236,  0.0620, -0.0542,  0.0664, -0.0142, -0.0848,  0.0158,\n",
              "          0.0078,  0.0722, -0.0348,  0.0021,  0.0306,  0.0472,  0.0324,  0.0730,\n",
              "         -0.0472, -0.0132, -0.0482, -0.0765,  0.0060, -0.0022, -0.0820,  0.0836,\n",
              "          0.0571, -0.0806, -0.0201, -0.0781, -0.0184, -0.0377,  0.0386, -0.0560,\n",
              "         -0.0486,  0.0184,  0.0197,  0.0317, -0.0104, -0.0151, -0.0519,  0.0139,\n",
              "         -0.0802, -0.0447, -0.0387,  0.0386,  0.0880, -0.0072,  0.0201, -0.0030,\n",
              "          0.0482, -0.0096, -0.0077,  0.0361,  0.0847,  0.0055, -0.0643,  0.0465,\n",
              "          0.0406, -0.0009,  0.0401, -0.0235, -0.0400,  0.0518,  0.0083, -0.0445],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[ 9.0081e-02,  3.7356e-02,  6.9710e-02,  8.8236e-02, -7.6234e-02,\n",
              "          -7.1345e-02, -7.7375e-02, -3.8745e-02, -5.5168e-02, -8.7096e-02,\n",
              "          -3.7569e-02,  3.9388e-02, -3.2583e-02, -1.0664e-01,  4.9055e-02,\n",
              "          -1.0159e-01,  1.0272e-01, -1.1402e-01, -4.7686e-02, -5.7525e-02,\n",
              "          -7.0537e-02, -7.4671e-02,  9.4336e-03, -4.0117e-02,  5.6997e-02,\n",
              "          -5.3749e-02,  8.2347e-02, -5.2436e-02, -2.4491e-02, -8.7979e-02,\n",
              "          -1.1973e-01, -1.1466e-01, -9.5454e-02, -5.4170e-02,  9.2472e-02,\n",
              "           1.0854e-01,  7.0513e-02, -5.2402e-02,  4.8631e-02, -6.2836e-02,\n",
              "          -2.3245e-02, -1.0050e-01, -1.0215e-01,  1.0455e-01, -4.8389e-02,\n",
              "           7.1216e-02,  3.2524e-02,  9.8147e-02,  3.4432e-02, -1.2261e-01,\n",
              "          -5.0106e-02,  1.4680e-03,  1.1862e-01, -1.1631e-01, -5.0776e-02,\n",
              "          -7.0127e-02,  7.8676e-02,  8.7946e-03, -8.8729e-02, -2.0927e-02,\n",
              "           8.7050e-02, -6.5049e-02, -1.2278e-01, -1.1287e-01],\n",
              "         [ 1.0436e-01,  7.6212e-02,  6.4923e-02, -6.8517e-02,  9.1888e-02,\n",
              "          -5.7796e-02, -4.8501e-02,  7.0289e-03, -1.1883e-02, -1.1316e-01,\n",
              "          -1.0312e-01,  1.1598e-01,  1.0378e-01,  6.4732e-02, -3.0224e-02,\n",
              "           1.0506e-01,  6.5341e-02,  8.2837e-02, -5.0905e-02,  4.1465e-02,\n",
              "          -1.7473e-02, -1.1618e-02, -4.3505e-02, -7.1211e-02, -7.1271e-02,\n",
              "           1.0543e-01, -1.0947e-01, -5.7232e-02,  6.1249e-03, -3.7144e-02,\n",
              "           2.3224e-02, -5.9947e-02,  1.6376e-03,  1.2366e-01, -4.7736e-02,\n",
              "          -2.8593e-02, -5.7356e-02, -7.6966e-03,  1.8551e-02,  1.0777e-01,\n",
              "           9.3941e-02, -1.1275e-01,  3.3747e-02,  6.9843e-02, -1.1245e-01,\n",
              "          -1.6102e-02,  4.3754e-02, -9.2891e-02,  4.1295e-02, -1.1135e-02,\n",
              "           1.1505e-01, -8.9256e-02, -1.7902e-02, -4.8278e-02, -5.9948e-02,\n",
              "          -6.9054e-02, -9.5287e-02,  5.1958e-02, -9.6191e-02, -8.1333e-02,\n",
              "          -1.1831e-01, -5.0818e-02,  1.9617e-02,  6.0398e-02],\n",
              "         [ 4.6233e-02, -7.4481e-03,  5.9582e-02, -8.4784e-02, -4.4886e-02,\n",
              "          -5.7918e-02,  1.8280e-03,  3.3014e-02, -5.5287e-02, -9.9929e-02,\n",
              "          -1.1454e-01,  8.0611e-02, -2.7632e-02, -9.3177e-03,  4.8162e-02,\n",
              "           2.9989e-02,  7.0339e-02,  8.0662e-02,  7.6884e-02, -1.0435e-01,\n",
              "          -9.5663e-02, -1.1426e-01,  5.1286e-02, -1.1938e-01,  2.6427e-02,\n",
              "          -1.4849e-02,  2.3778e-02, -6.7329e-02, -1.3762e-02, -9.7381e-02,\n",
              "           7.1157e-02, -9.7582e-02, -1.0893e-01,  6.7438e-02, -4.4392e-02,\n",
              "           6.7494e-02, -8.1297e-02,  5.8845e-02,  7.1351e-02,  2.1815e-02,\n",
              "           1.6142e-02, -3.6674e-02, -9.6215e-02,  7.3477e-02, -3.5439e-02,\n",
              "           6.6271e-02, -4.8064e-03,  8.6875e-02, -3.4575e-02,  6.1419e-02,\n",
              "           7.0954e-02, -9.9163e-02,  1.1564e-01, -8.3721e-02, -3.5193e-02,\n",
              "          -7.7610e-02,  1.1441e-01, -1.5756e-02,  2.9517e-02, -1.0107e-01,\n",
              "           7.8556e-02, -9.6974e-02, -6.5762e-02,  1.4813e-02],\n",
              "         [-7.1689e-02, -7.0438e-02, -1.0442e-01, -1.0223e-01,  2.8575e-02,\n",
              "          -1.1557e-02, -8.9722e-02,  4.6953e-02,  8.5471e-03, -9.9298e-02,\n",
              "          -4.4833e-02,  8.7817e-02,  2.4296e-03, -8.6734e-03,  6.1460e-02,\n",
              "          -1.1059e-01,  3.2985e-02, -6.3782e-02, -8.4176e-02,  2.6103e-02,\n",
              "           7.7581e-02,  5.0593e-02, -4.8968e-02, -3.1030e-02,  8.8692e-02,\n",
              "          -4.6854e-02, -3.9124e-02, -8.7372e-02,  4.9841e-02,  9.3803e-02,\n",
              "           1.0251e-01,  7.4574e-02, -2.3162e-02, -1.0604e-01, -2.0008e-02,\n",
              "           5.1987e-02, -4.0634e-02,  4.5314e-02, -1.1238e-01,  2.7515e-02,\n",
              "           4.6227e-02, -4.4695e-02, -4.1887e-03,  7.9416e-02,  8.5800e-02,\n",
              "           1.1527e-01, -6.2579e-02,  8.3028e-02,  7.0645e-02, -1.1405e-01,\n",
              "          -1.1954e-01,  1.4401e-03,  5.5466e-02, -4.0129e-03,  2.7050e-02,\n",
              "          -2.8181e-02,  2.1803e-02,  1.1188e-01, -1.7074e-03,  9.0480e-02,\n",
              "           6.9893e-03, -1.0761e-01,  1.5924e-02,  7.1381e-02],\n",
              "         [ 2.3589e-02,  8.1676e-02, -7.0783e-03, -5.7389e-02, -1.9109e-02,\n",
              "          -1.2100e-01, -4.7284e-02, -1.1375e-01,  5.1138e-02, -8.3358e-02,\n",
              "          -3.3024e-02,  9.6124e-02,  1.1774e-01, -4.0486e-02,  3.7960e-02,\n",
              "           6.2728e-02,  3.2087e-02,  2.3017e-02, -1.0746e-01,  5.5915e-02,\n",
              "          -1.6560e-02,  9.0140e-02, -1.1005e-01,  3.2534e-02, -1.0647e-01,\n",
              "          -7.2678e-03, -4.0964e-02, -1.7662e-02,  1.4631e-02, -7.0268e-02,\n",
              "          -4.5365e-02, -6.2733e-02,  5.2360e-02,  3.3188e-04, -1.4908e-02,\n",
              "           8.6073e-02,  5.3087e-03,  9.9666e-02, -1.0756e-01, -9.1940e-02,\n",
              "           7.7558e-02, -6.5246e-03,  7.9211e-02,  6.2014e-02,  9.1240e-02,\n",
              "          -7.2042e-02,  9.5041e-02, -1.8821e-02,  5.3471e-02, -2.2709e-03,\n",
              "          -8.1674e-02,  5.8469e-02, -1.8044e-02,  7.5014e-03,  2.7437e-02,\n",
              "           4.8671e-02,  3.1838e-02,  1.6095e-02, -1.8188e-02, -1.8133e-02,\n",
              "           6.9220e-02, -2.3845e-02, -3.9307e-02,  8.9694e-02],\n",
              "         [ 7.8863e-02, -4.5143e-03, -1.7035e-02,  7.6391e-02, -3.8876e-02,\n",
              "          -4.0176e-02, -3.6997e-02,  2.4401e-02,  2.1845e-02,  4.9310e-03,\n",
              "           1.2447e-01, -1.9493e-02,  7.6409e-02,  9.8022e-02,  5.4328e-02,\n",
              "          -6.2399e-02,  1.1802e-01, -5.1641e-02,  7.3480e-02, -5.2663e-02,\n",
              "           6.3537e-02, -6.2841e-02,  1.0797e-01, -9.1990e-02, -1.1369e-02,\n",
              "          -9.6867e-02, -1.1386e-01, -8.5889e-02,  5.4013e-03, -5.4728e-02,\n",
              "           6.7700e-02, -7.4272e-02,  4.1084e-02,  6.6796e-02,  1.9199e-02,\n",
              "          -3.5821e-02, -7.3575e-02, -6.3345e-02, -7.8905e-02,  1.9517e-02,\n",
              "           1.1469e-04,  3.5825e-02, -1.3905e-02,  9.5397e-02, -8.0964e-02,\n",
              "           6.7808e-02, -8.1335e-02, -3.5128e-02, -9.6693e-02,  1.6782e-02,\n",
              "          -6.1780e-02, -1.0872e-01,  1.6121e-02,  3.9216e-03,  5.5421e-02,\n",
              "          -7.2117e-02, -6.0131e-02, -8.6066e-02, -6.3648e-02, -9.6916e-02,\n",
              "          -1.1963e-01,  7.3061e-02, -9.7729e-02,  1.0952e-01],\n",
              "         [-1.2224e-02,  9.1739e-02,  2.6054e-03,  9.2386e-02, -7.7299e-02,\n",
              "           5.7100e-02,  6.3257e-02,  5.3884e-02,  7.7071e-02, -8.3343e-02,\n",
              "           9.4976e-02,  6.4131e-02, -1.2372e-01, -2.0569e-02,  7.4856e-02,\n",
              "          -6.8663e-02,  6.5786e-02, -9.5862e-02, -9.0798e-02,  6.8922e-02,\n",
              "           5.8374e-03, -9.7912e-02, -1.2454e-01, -1.6876e-02, -6.7895e-02,\n",
              "           1.4116e-02, -1.2117e-01,  1.1049e-01, -6.2181e-02, -1.1762e-01,\n",
              "           9.5500e-02,  9.3268e-02,  3.9143e-02, -3.9007e-02,  9.0827e-03,\n",
              "           6.2115e-02, -3.8073e-02,  9.1955e-03,  6.0296e-02, -3.1423e-02,\n",
              "           5.7925e-02, -5.8846e-02, -6.2736e-03,  1.7145e-02, -2.2281e-03,\n",
              "          -3.9474e-02,  1.1919e-01,  8.9112e-03, -1.1609e-01, -6.6616e-02,\n",
              "           9.1850e-03,  9.6228e-02, -1.0598e-01,  3.6934e-02, -2.4756e-03,\n",
              "          -9.0299e-02, -1.0841e-01, -6.0290e-05,  5.8022e-02,  5.0343e-03,\n",
              "           1.2500e-01, -1.1109e-01,  2.6558e-02,  4.8932e-02],\n",
              "         [-4.6378e-02,  8.9418e-02,  4.4312e-02, -1.7517e-02, -1.6468e-02,\n",
              "          -1.1285e-01, -1.8747e-02, -6.3244e-03, -7.7638e-03, -2.3948e-02,\n",
              "          -3.2446e-02,  9.5390e-02, -2.7532e-02,  5.8011e-03,  1.1339e-01,\n",
              "           5.7117e-02, -6.7388e-02, -1.1449e-01,  1.0384e-01, -4.4569e-02,\n",
              "          -6.8958e-02, -4.7796e-02, -4.7658e-02, -1.1955e-01, -7.6193e-02,\n",
              "           3.1827e-02,  1.8047e-02,  6.9459e-02, -4.5596e-02,  2.9646e-02,\n",
              "           3.7715e-02, -1.1099e-01, -1.2415e-01,  1.1874e-01,  1.7708e-02,\n",
              "           1.3392e-02,  1.5441e-02, -4.0768e-02, -2.7820e-02,  4.5540e-02,\n",
              "          -1.1272e-01, -6.5822e-02, -9.2716e-02,  7.3224e-02,  3.5008e-03,\n",
              "          -8.8429e-02, -5.5867e-02,  1.0458e-01, -2.0049e-02,  4.0491e-02,\n",
              "           8.7442e-02,  7.1912e-02, -1.8908e-02,  1.1014e-01,  9.6440e-02,\n",
              "           1.2370e-01,  6.9982e-02, -2.7373e-02, -1.1226e-01,  4.2441e-02,\n",
              "          -2.5733e-02,  1.5014e-02,  9.0602e-04, -4.3412e-02],\n",
              "         [-2.5994e-02, -2.8367e-02, -6.7998e-02,  6.3442e-03, -3.1602e-02,\n",
              "           4.8795e-02,  2.3254e-02, -6.2824e-02,  5.2419e-02, -2.3225e-03,\n",
              "           1.3899e-02, -4.5344e-02, -2.0702e-02, -3.1494e-02,  2.9391e-02,\n",
              "           7.6477e-02, -1.5702e-02, -2.2456e-02,  1.1494e-02,  7.1579e-02,\n",
              "           5.3069e-02, -1.2139e-01,  1.0992e-01, -2.9662e-02, -9.3404e-02,\n",
              "           4.0606e-02,  3.0610e-02, -6.3863e-02,  3.2957e-02,  1.5685e-03,\n",
              "           1.1990e-01,  1.6607e-02,  3.5230e-02,  3.6362e-02,  1.1741e-01,\n",
              "          -1.0202e-01,  7.0930e-02, -4.0306e-02, -1.0033e-01, -7.3437e-03,\n",
              "           3.6457e-02,  8.0335e-02,  8.7448e-03,  5.1849e-02, -5.5932e-02,\n",
              "           5.5974e-02,  7.4239e-02,  8.2881e-02,  1.6682e-02, -8.6252e-02,\n",
              "          -5.9268e-02,  1.3023e-02, -3.8033e-02,  9.2538e-02, -8.9049e-03,\n",
              "          -5.8281e-02, -1.7585e-02,  1.6728e-02,  1.0442e-01, -7.5990e-02,\n",
              "           1.1596e-01,  2.4260e-02, -8.2568e-02,  5.4840e-02],\n",
              "         [ 9.3958e-02,  7.1076e-02, -2.3477e-02, -3.0570e-02, -4.2801e-02,\n",
              "          -3.7062e-02,  3.1778e-02, -1.4623e-02, -1.1299e-01, -8.4478e-02,\n",
              "           1.0354e-01,  3.3000e-03,  9.3768e-02, -5.5890e-02,  8.0037e-02,\n",
              "          -1.1467e-01, -5.7062e-03, -7.7923e-04,  3.0943e-02,  1.6023e-02,\n",
              "           1.0476e-01,  5.7078e-02, -8.4059e-02, -3.2775e-02,  3.5241e-02,\n",
              "           1.2878e-02,  1.0535e-01,  1.1410e-01,  7.7023e-02,  1.0729e-01,\n",
              "           7.7628e-02,  1.1527e-01,  9.4729e-02,  2.3800e-02, -5.9765e-02,\n",
              "          -4.2081e-02, -1.2294e-01,  1.6422e-02,  6.0624e-02,  4.7498e-02,\n",
              "           1.6913e-02, -9.0125e-02, -2.3990e-03, -3.2058e-02,  4.3437e-02,\n",
              "          -6.3255e-02, -4.7269e-02, -6.7232e-02,  1.3839e-02,  5.8610e-02,\n",
              "          -1.0842e-01, -6.8193e-02, -1.1814e-04,  8.5391e-03,  8.7461e-02,\n",
              "          -6.8934e-03, -7.9324e-02,  1.0197e-01, -5.0869e-02,  6.6448e-03,\n",
              "          -1.1987e-01,  6.9663e-02,  8.7548e-02, -1.1457e-02]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.1229, -0.1011, -0.0894, -0.0327, -0.0978,  0.1086,  0.0768, -0.0979,\n",
              "         -0.1077, -0.0350], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.5)"
      ],
      "metadata": {
        "id": "EKUuM3UvUZm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    model.train()\n",
        "    # 배치 당 loss 값을 담을 리스트 생성\n",
        "    batch_losses = []\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        # 옵티마이저의 기울기 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # y pred 값 산출\n",
        "        output = model(data)\n",
        "        # loss 계산\n",
        "        # 정답 데이터와의 cross entropy loss 계산\n",
        "        # 이 loss를 배치 당 loss로 보관\n",
        "        loss = criterion(output, target)\n",
        "        batch_losses.append(loss)\n",
        "\n",
        "        # 기울기 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 가중치 업데이트!\n",
        "        optimizer.step()\n",
        "        \n",
        "    # 배치당 평균 loss 계산\n",
        "    avg_loss = sum(batch_losses) / len(batch_losses)\n",
        "    \n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "-QDRH5a6T_dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    # 모델을 평가 모드로 전환\n",
        "    model.eval()\n",
        "\n",
        "    batch_losses = []\n",
        "    correct = 0 \n",
        "\n",
        "    with torch.no_grad(): \n",
        "        for data, target in test_loader:\n",
        "            # 예측값 생성\n",
        "            output = model(data)\n",
        "\n",
        "            # loss 계산 (이전과 동일)\n",
        "            loss = criterion(output, target)\n",
        "            batch_losses.append(loss)\n",
        "\n",
        "           # Accuracy 계산\n",
        "           # y pred와 y가 일치하면 correct에 1을 더해주기\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "\n",
        "            # eq() 함수는 값이 일치하면 1을, 아니면 0을 출력.\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # 배치 당 평균 loss 계산 \n",
        "    avg_loss =  sum(batch_losses) / len(batch_losses)\n",
        "\n",
        "    #정확도 계산\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "Yytz01oJi_6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    \n",
        "    print('[{}] Train Loss: {:.4f}\\tTest Loss: {:.4f}\\tAccuracy: {:.2f}%'.format(\n",
        "          epoch, train_loss, test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "xuBakS2vY9DP",
        "outputId": "e3f33098-1152-4f59-d193-604beaee1fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Train Loss: 0.8365\tTest Loss: 0.2869\tAccuracy: 91.30%\n",
            "[2] Train Loss: 0.2499\tTest Loss: 0.2225\tAccuracy: 93.33%\n",
            "[3] Train Loss: 0.2358\tTest Loss: 0.1817\tAccuracy: 94.13%\n",
            "[4] Train Loss: 0.1408\tTest Loss: 0.1862\tAccuracy: 93.98%\n",
            "[5] Train Loss: 0.1177\tTest Loss: 0.1488\tAccuracy: 95.18%\n",
            "[6] Train Loss: 0.0953\tTest Loss: 0.1017\tAccuracy: 96.89%\n",
            "[7] Train Loss: 0.0815\tTest Loss: 0.0895\tAccuracy: 97.03%\n",
            "[8] Train Loss: 0.0715\tTest Loss: 0.0939\tAccuracy: 97.05%\n",
            "[9] Train Loss: 0.0616\tTest Loss: 0.0856\tAccuracy: 97.44%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-952f2527f3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-a7fef517b09a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# 옵티마이저의 기울기 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaqqRzF73oBu"
      },
      "source": [
        "## 과제 4\n",
        "과제 3 부분의 성능을 지금까지 배운 지식을 바탕으로 향상시켜보세요\n",
        "\n",
        "- Hint : Activation function, hyperparameter setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6b82DZG6W3j"
      },
      "source": [
        "# Assignment 4 구현은 여기서 ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "# train set과 test set 각각에 대하여 DataLoader를 생성합니다.\n",
        "# shuffle=True 매개변수를 넣어 데이터를 섞어주세요.\n",
        "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader =  DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "IncDJtJOyq8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "iSHRTuxfpfvW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_2, self).__init__()\n",
        "        self.layer1 = nn.Linear(784,128)\n",
        "        torch.nn.init.xavier_uniform_(self.layer1.weight)\n",
        "        self.layer2 = nn.Linear(128,64)\n",
        "        torch.nn.init.xavier_uniform_(self.layer2.weight)\n",
        "        self.layer3 = nn.Linear(64,10)\n",
        "        self.LeakyReLU = nn.LeakyReLU()\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        out = self.layer1(x)\n",
        "        out = self.LeakyReLU(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "lAHjB3djrxNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Net_2()"
      ],
      "metadata": {
        "id": "O30tskDBr2B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = train(model_2, train_loader, optimizer)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    \n",
        "    print('[{}] Train Loss: {:.4f}\\tTest Loss: {:.4f}\\tAccuracy: {:.2f}%'.format(\n",
        "          epoch, train_loss, test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m2WxQKSs7qw",
        "outputId": "978cd5f6-a8b5-46a6-daf4-cced9f42d9a3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Train Loss: 2.3144\tTest Loss: 0.0793\tAccuracy: 97.52%\n",
            "[2] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[3] Train Loss: 2.3144\tTest Loss: 0.0783\tAccuracy: 97.52%\n",
            "[4] Train Loss: 2.3144\tTest Loss: 0.0783\tAccuracy: 97.52%\n",
            "[5] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[6] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[7] Train Loss: 2.3143\tTest Loss: 0.0796\tAccuracy: 97.52%\n",
            "[8] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[9] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[10] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[11] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[12] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[13] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[14] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[15] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[16] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[17] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[18] Train Loss: 2.3143\tTest Loss: 0.0789\tAccuracy: 97.52%\n",
            "[19] Train Loss: 2.3144\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[20] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[21] Train Loss: 2.3144\tTest Loss: 0.0787\tAccuracy: 97.52%\n",
            "[22] Train Loss: 2.3144\tTest Loss: 0.0814\tAccuracy: 97.52%\n",
            "[23] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[24] Train Loss: 2.3143\tTest Loss: 0.0787\tAccuracy: 97.52%\n",
            "[25] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[26] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[27] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[28] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[29] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[30] Train Loss: 2.3143\tTest Loss: 0.0782\tAccuracy: 97.52%\n",
            "[31] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[32] Train Loss: 2.3144\tTest Loss: 0.0788\tAccuracy: 97.52%\n",
            "[33] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[34] Train Loss: 2.3144\tTest Loss: 0.0796\tAccuracy: 97.52%\n",
            "[35] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[36] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[37] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[38] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[39] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[40] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[41] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[42] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[43] Train Loss: 2.3143\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[44] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[45] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[46] Train Loss: 2.3143\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[47] Train Loss: 2.3143\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[48] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[49] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[50] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[51] Train Loss: 2.3143\tTest Loss: 0.0782\tAccuracy: 97.52%\n",
            "[52] Train Loss: 2.3144\tTest Loss: 0.0787\tAccuracy: 97.52%\n",
            "[53] Train Loss: 2.3144\tTest Loss: 0.0783\tAccuracy: 97.52%\n",
            "[54] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[55] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[56] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[57] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[58] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[59] Train Loss: 2.3143\tTest Loss: 0.0783\tAccuracy: 97.52%\n",
            "[60] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[61] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[62] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[63] Train Loss: 2.3143\tTest Loss: 0.0787\tAccuracy: 97.52%\n",
            "[64] Train Loss: 2.3144\tTest Loss: 0.0784\tAccuracy: 97.52%\n",
            "[65] Train Loss: 2.3143\tTest Loss: 0.0786\tAccuracy: 97.52%\n",
            "[66] Train Loss: 2.3144\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[67] Train Loss: 2.3144\tTest Loss: 0.0787\tAccuracy: 97.52%\n",
            "[68] Train Loss: 2.3144\tTest Loss: 0.0787\tAccuracy: 97.52%\n",
            "[69] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[70] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[71] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[72] Train Loss: 2.3144\tTest Loss: 0.0782\tAccuracy: 97.52%\n",
            "[73] Train Loss: 2.3143\tTest Loss: 0.0798\tAccuracy: 97.52%\n",
            "[74] Train Loss: 2.3144\tTest Loss: 0.0793\tAccuracy: 97.52%\n",
            "[75] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[76] Train Loss: 2.3143\tTest Loss: 0.0787\tAccuracy: 97.52%\n",
            "[77] Train Loss: 2.3144\tTest Loss: 0.0790\tAccuracy: 97.52%\n",
            "[78] Train Loss: 2.3144\tTest Loss: 0.0789\tAccuracy: 97.52%\n",
            "[79] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[80] Train Loss: 2.3144\tTest Loss: 0.0784\tAccuracy: 97.52%\n",
            "[81] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[82] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[83] Train Loss: 2.3143\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[84] Train Loss: 2.3144\tTest Loss: 0.0782\tAccuracy: 97.52%\n",
            "[85] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[86] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[87] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[88] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[89] Train Loss: 2.3144\tTest Loss: 0.0784\tAccuracy: 97.52%\n",
            "[90] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[91] Train Loss: 2.3144\tTest Loss: 0.0780\tAccuracy: 97.52%\n",
            "[92] Train Loss: 2.3143\tTest Loss: 0.0792\tAccuracy: 97.52%\n",
            "[93] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[94] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[95] Train Loss: 2.3143\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[96] Train Loss: 2.3143\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[97] Train Loss: 2.3144\tTest Loss: 0.0781\tAccuracy: 97.52%\n",
            "[98] Train Loss: 2.3144\tTest Loss: 0.0784\tAccuracy: 97.52%\n",
            "[99] Train Loss: 2.3144\tTest Loss: 0.0779\tAccuracy: 97.52%\n",
            "[100] Train Loss: 2.3143\tTest Loss: 0.0780\tAccuracy: 97.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss 가 잘 줄어들지 않아 Lr을 조정하였습니다. \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "hz7HCT6Y-E_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = train(model_2, train_loader, optimizer)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    \n",
        "    print('[{}] Train Loss: {:.4f}\\tTest Loss: {:.4f}\\tAccuracy: {:.2f}%'.format(\n",
        "          epoch, train_loss, test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "QS1nr1uc-AXV",
        "outputId": "b3bf46f8-19a6-4c08-ea34-e2a3009d8fcf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Train Loss: 2.3143\tTest Loss: 0.0791\tAccuracy: 97.52%\n",
            "[2] Train Loss: 2.3143\tTest Loss: 0.0783\tAccuracy: 97.52%\n",
            "[3] Train Loss: 2.3144\tTest Loss: 0.0784\tAccuracy: 97.52%\n",
            "[4] Train Loss: 2.3144\tTest Loss: 0.0789\tAccuracy: 97.52%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-4e898608717b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-a7fef517b09a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# 옵티마이저의 기울기 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch: 60000, lr=0.01, xavier initialization for layer1, 2 results in about 94...and more\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m9NRCRJ6z2mI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DiXWRBWLr12f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pboMIBQq7onH"
      },
      "source": [
        "**무엇을 보완하였고, 왜 보완되었는지에 대한 자유 서술 (아래에)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. optimizer - > SGD 에서 adam으로 바꿔보도록 하였습니다\n",
        "-> 보편화된 optimizer는 adam을 주로 설정하기 때문입니다\n",
        " 2. learning rate를 낮추도록 조정하였습니다.  \n",
        " -> 이유는 accuracy가 수렴하지 못하고 학습동안 느리게 수렴하였기 때문입니다. \n",
        "\n",
        " 3.  활성화 함수로 Leaky ReLu 를 추가하였습니다! \n",
        " ->  "
      ],
      "metadata": {
        "id": "tBQqEtTppjvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 가중치 초기화를 진행하였습니다 \n",
        "->  초기값 설정이 학습과정에 매우 큰 영향을 끼칠 수 있기 때문에\n",
        "\n"
      ],
      "metadata": {
        "id": "ynSfR3D6jdIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zuATLziRjWcq"
      }
    }
  ]
}