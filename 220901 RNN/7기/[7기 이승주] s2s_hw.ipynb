{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhqgooEJc3ml"
      },
      "source": [
        "# PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6JAywISdMna"
      },
      "source": [
        "구글 드라이브"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KzgUpIpcORE",
        "outputId": "5de61d17-ee2b-4706-f573-fbb7c45c5039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# 지금 RNN이란 폴더에서 작업해서 RNN으로 맞춘 상태입니다! \n",
        "os.chdir('/content/drive/My Drive/RegularSession/[20220901]RNN/RNN 과제')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TK1fCrA9fHwN",
        "outputId": "00a889f2-74c8-4ce4-cac0-0477d0d0d125"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/RegularSession/[20220901]RNN/RNN 과제'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_data = f\"{os.getcwd()}/data/data_hw\"\n",
        "root_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yR9lFnfZMQ8k",
        "outputId": "4fc7f8bb-f693-4c3b-820b-ecb962082b52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/RegularSession/[20220901]RNN/RNN 과제/data/data_hw'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러올 때 사용할 경로로 이후에 있을 unzip과 연동되는 내용입니다! \n",
        "path_train_data = \"data/data_hw/1.Training/원천데이터/일상생활및구어체_영한_train_set.json\"\n",
        "\n",
        "path_val_data = \"data/data_hw/2.Validation/원천데이터/일상생활및구어체_영한_valid_set.json\"\n"
      ],
      "metadata": {
        "id": "eUaOJiEaP8t9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사전 준비 사항"
      ],
      "metadata": {
        "id": "lllM7QIsLKHG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N4M6g36zarsi"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8nWTk5MXatC-"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oV91g9Tqa0V0",
        "outputId": "3eca9d6a-6e49-4423-d449-5ea0a2ca19bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdN8CiTlc7xF"
      },
      "source": [
        "# Data\n",
        "\n",
        "실습에서 사용했던 영어-프랑스어와 달리 현재 사용할 데이터 셋은 영어-한국어 데이터 셋입니다. \n",
        "\n",
        "특히 압축을 풀어야 사용하실 수 있으니 유의하여 진행해주시길 바랍니다.\n",
        "\n",
        "다행인 점은 용량이 그리 크지 않을겁니다!\n",
        "\n",
        "저장 경로는 위에서 path_train_data와 path_val_data와 동일하게 맞췄습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq data/data_hw/1.Training/원천데이터/TS1.zip -d data/data_hw/1.Training/원천데이터\n",
        "\n",
        "!unzip -qq data/data_hw/2.Validation/원천데이터/VS1.zip -d data/data_hw/2.Validation/원천데이터\n"
      ],
      "metadata": {
        "id": "4bGHHia2LnOo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 구조 확인"
      ],
      "metadata": {
        "id": "tfrW60WrP0rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "SDeLynUqP0Jr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로는 앞서 PATH에서 선언했고 unzip에서도 경로를 지정했습니다. 만약 여기에 변화가 생기신다면 에러가 생길 수 있으니 유의하셔야 합니다.\n",
        "with open(path_train_data, 'r') as f:\n",
        "  raw_train_data = json.load(f)\n",
        "\n",
        "with open(path_val_data, 'r') as f:\n",
        "  raw_val_data = json.load(f)\n"
      ],
      "metadata": {
        "id": "2VEmaNPbP5hr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 데이터의 구조가 {'data':~~~ }로 되어있는것을 알 수 있습니다.\n",
        "raw_train_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNhgtA6iR2HG",
        "outputId": "35f14683-0063-433f-d365-504fb0f51efd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 개수 확인\n",
        "len(raw_train_data['data'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMcJ230kRgJ_",
        "outputId": "39d7c069-79ee-482a-ddcf-ae4f4bceb519"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200307"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금 데이터가 너무 많아서 전처리만 해도 1,2시간 걸릴 수 있습니다. 그래서 숙제에서는 매우 일부 데이터만 이용하도록 하겠습니다."
      ],
      "metadata": {
        "id": "pOcoZtgOYicO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_data = raw_train_data['data'][:10000]\n",
        "raw_val_data = raw_val_data['data'][:1000]"
      ],
      "metadata": {
        "id": "OXGulbjhYg-o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플로 하나 확인\n",
        "sample_data = raw_train_data[0]"
      ],
      "metadata": {
        "id": "GMFaFQF0SJb4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래의 예시를 보고 데이터를 어떻게 처리할지 잘 생각하셔야 합니다!\n",
        "# 보았을 때 우리가 사용해야 하는 건 ko와 en가 되고\n",
        "# 실제 데이터를 사용한다고 할 때 이 외에 필요한 데이터가 더 있을 수 있습니다.\n",
        "# 모델링 과정에서는 어떻게 데이터들이 저장되어 있는지 주의해서 처리하시면 됩니다.\n",
        "sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I68Quh9gSRag",
        "outputId": "37bc676d-8372-4ff1-c4cc-cc85dd3345b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sn': 'ECOAR1A00003',\n",
              " 'data_set': '일상생활및구어체',\n",
              " 'domain': '해외고객과의채팅',\n",
              " 'subdomain': '숙박,음식점',\n",
              " 'en_original': \"I'm glad to hear that, and I hope you do consider doing business with us.\",\n",
              " 'en': \"I'm glad to hear that, and I hope you do consider doing business with us.\",\n",
              " 'mt': '그 소식을 들으니 기쁩니다. 우리와 거래하는 것을 고려해 보시기 바랍니다.',\n",
              " 'ko': '그 말을 들으니 기쁘고, 저희와 거래하는 것을 고려해 주셨으면 합니다.',\n",
              " 'source_language': 'en',\n",
              " 'target_language': 'ko',\n",
              " 'word_count_ko': 10.0,\n",
              " 'word_count_en': 15.0,\n",
              " 'word_ratio': 0.667,\n",
              " 'file_name': '해외고객과의채팅_숙박,음식점.xlsx',\n",
              " 'source': '크라우드 소싱',\n",
              " 'license': 'open',\n",
              " 'style': '구어체',\n",
              " 'included_unknown_words': False,\n",
              " 'ner': None}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoZkQRO3l20O"
      },
      "source": [
        "# Preprocess\n",
        "\n",
        "세션 설명 코드에서는 알파벳 하나하나 사용했지만, 이번 과정에서는 토큰화를 진행하여 사용하는 과정을 Dataset에 바로 적용해보고자 합니다! \n",
        "\n",
        "토큰화는 앞서 word embedding 세션에서 사용한 것들을 그대로 이용하고자 합니다. 세부 커스터마이징은 자유롭습니다.\n",
        "\n",
        "전처리 과정에서 중요한 점은, 앞의 구현 코드에서 여러 개의 for loop을 이용해서 구현했었지만, 실제 데이터를 사용한다면 매우 오래 걸리게 됩니다. 실제 데이터를 사용할 때엔 결국 얼마나 효율적으로 빠르게 정리할 수 있을지 고민해보시면서 접근하시길 바랍니다.\n",
        "\n",
        "즉, 전처리에서 챙길 통찰은 얼마나 \"효율적\"으로 할 수 있는가? 입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "IngQKWx3VRtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#konlpy 설치 (mecab 제외). 3~40초 정도 소요\n",
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttmiDFAEU_BK",
        "outputId": "76edd033-8841-46c8-9583-9437b7e00a29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [91.7 kB]\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,396 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,172 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,105 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,965 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,079 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,540 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,131 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.2 kB]\n",
            "Fetched 13.8 MB in 3s (4,875 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "g++ set to manually installed.\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs openjdk-8-demo openjdk-8-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 15 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 46.0 MB of archives.\n",
            "After this operation, 166 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u342-b07-0ubuntu1~18.04 [28.3 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u342-b07-0ubuntu1~18.04 [69.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u342-b07-0ubuntu1~18.04 [8,300 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u342-b07-0ubuntu1~18.04 [4,032 kB]\n",
            "Fetched 46.0 MB in 1s (59.5 MB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 155685 files and directories currently installed.)\r\n",
            "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\r\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\r\n",
            "Selecting previously unselected package fonts-dejavu-core.\r\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\r\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\r\n",
            "Selecting previously unselected package fonts-dejavu-extra.\r\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\r\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\r\n",
            "Selecting previously unselected package x11-utils.\r\n",
            "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\r\n",
            "Unpacking x11-utils (7.7+3build1) ...\r\n",
            "Selecting previously unselected package libatk-wrapper-java.\r\n",
            "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\r\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\r\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\r\n",
            "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\r\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\r\n",
            "Selecting previously unselected package libgtk2.0-common.\r\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\r\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\r\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libgail18:amd64.\r\n",
            "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libgail-common:amd64.\r\n",
            "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libgtk2.0-bin.\r\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\r\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\r\n",
            "Preparing to unpack .../11-openjdk-8-jre-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\r\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\r\n",
            "Preparing to unpack .../12-openjdk-8-jre_8u342-b07-0ubuntu1~18.04_amd64.deb ...\r\n",
            "Unpacking openjdk-8-jre:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\r\n",
            "Preparing to unpack .../13-openjdk-8-jdk-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\r\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\r\n",
            "Preparing to unpack .../14-openjdk-8-jdk_8u342-b07-0ubuntu1~18.04_amd64.deb ...\r\n",
            "Unpacking openjdk-8-jdk:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\r\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\r\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\r\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\r\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\r\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\r\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\r\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\r\n",
            "Setting up x11-utils (7.7+3build1) ...\r\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\r\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\r\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\r\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\r\n",
            "Setting up openjdk-8-jre:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\r\n",
            "Setting up openjdk-8-jdk:amd64 (8u342-b07-0ubuntu1~18.04) ...\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\r\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\r\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\r\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\r\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\r\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting JPype1\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1) (4.1.1)\n",
            "Installing collected packages: JPype1\n",
            "Successfully installed JPype1-1.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: konlpy\n",
            "Successfully installed konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# java 경로 설정\n",
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV7CNL2KVDqN",
        "outputId": "fb9cff57-e4e7-4631-bd10-3f92dad7bea5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "S0aHtzksVPOT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()"
      ],
      "metadata": {
        "id": "ly1Fg2bXVYVF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CustomTokenizer(corpus):\n",
        "    tokenized = []\n",
        "    stop = ['Josa','Suffix','Punctuation', 'Foreign', 'Number']\n",
        "    for i, j in okt.pos(corpus, stem = True, norm = True):\n",
        "        if j in stop:\n",
        "            continue\n",
        "        tokenized.append(i)\n",
        "    return tokenized        "
      ],
      "metadata": {
        "id": "UcXNpcUaVtIA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 처리 어떻게 되고 있는지 확인\n",
        "CustomTokenizer(sample_data['ko'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGMdyWtdWF31",
        "outputId": "8c4a89f3-b675-4c5d-e071-cf032e4aaa5d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['그', '말', '들다', '기쁘다', '저희', '거래', '하다', '것', '고려', '하다', '주다', '하다']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어도 일단 토큰화가 되고 있으니 사용해보도록 합시다\n",
        "CustomTokenizer(sample_data['en'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7vMH186WJUp",
        "outputId": "22ed4bb8-714a-45c0-d114-0410c68aa473"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'm',\n",
              " 'glad',\n",
              " 'to',\n",
              " 'hear',\n",
              " 'that',\n",
              " 'and',\n",
              " 'I',\n",
              " 'hope',\n",
              " 'you',\n",
              " 'do',\n",
              " 'consider',\n",
              " 'doing',\n",
              " 'business',\n",
              " 'with',\n",
              " 'us']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 본격적인 전처리 과정\n",
        "\n",
        "전처리릏 할 때 주의할 점은, 우리가 가지고 있는 것은 train 데이터 뿐이라는 점입니다.\n",
        "\n",
        "토큰화를 하고, token들을 수집할 때 평가데이터(혹은 테스트 데이터)에 대한 정보는 가지고 있을 수 없습니다. 그렇기 때문에 train data를 기준으로 전처리가 진행되어야 합니다."
      ],
      "metadata": {
        "id": "L9_z0sVcW7Cy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "HgfddQJuaQe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "zPHGhgX4YXJR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = set()\n",
        "tar_vocab = set()\n",
        "\n",
        "src_seq_tr = []\n",
        "tar_seq_tr = []\n",
        "\n",
        "# 전체 raw data에서 문장하나씩 loop 돌아가는 것\n",
        "for raw_tr_dat in tqdm(raw_train_data):\n",
        "  # 문장별 tokenization\n",
        "  src_tmp = CustomTokenizer(raw_tr_dat['ko'])\n",
        "  tar_tmp = CustomTokenizer(raw_tr_dat['en'])\n",
        "\n",
        "  # 입력 시퀀스에서 문장의 끝을 알리는 <EOS> 토큰 추가\n",
        "  # 출력 시퀀스에서 시작과 끝을 알리는 <SOS>, <EOS> 토큰 추가\n",
        "  src_tmp.append('<EOS>')\n",
        "  tar_tmp.append('<EOS>')\n",
        "  tar_tmp.insert(0, '<SOS>')\n",
        "\n",
        "  # 한국어, 영어 단어집합 구성\n",
        "  #src_vocab = \n",
        "  #tar_vocab = ~~~\n",
        "  for char in src_tmp:\n",
        "    src_vocab.add(char)\n",
        "  for char in tar_tmp:\n",
        "    tar_vocab.add(char)\n",
        "\n",
        "  # tokenization 끝난 문장 보관\n",
        "  src_seq_tr.append(src_tmp)\n",
        "  tar_seq_tr.append(tar_tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJjWUAipWPsN",
        "outputId": "ffc3a251-f999-414f-c039-1825d09ddb92"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:55<00:00, 179.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "고민해볼 점: 과연 한국어 단어집합에 한국어만 있을까요?\n",
        "\n",
        "지금 단계에서는 시간 상 체크하진 않지만 고민해볼 부분이기도 합니다."
      ],
      "metadata": {
        "id": "PtNW4DUIyEbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### token - index 정리"
      ],
      "metadata": {
        "id": "cK_E98-daSy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 정수 인코딩 하기 전 보기 편하기 위해 sort\n",
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))"
      ],
      "metadata": {
        "id": "Iz3i3MtRZ-P-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# token - idx dictionary\n",
        "# 여기서도 동일하게 i+1로 해줘야 padding에 사용할 token을 0으로 사용할 수 있습니다!\n",
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])"
      ],
      "metadata": {
        "id": "zncLWJou7ctd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_vocab[:5])\n",
        "print(tar_vocab[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF2hoEks9RL8",
        "outputId": "8e52c45c-f931-4175-bc3a-1b0f406463b7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<EOS>', 'A', 'AAA', 'AAA1@BBB1.com', 'AAA@BBB.com']\n",
            "['<EOS>', '<SOS>', 'A', 'AAA', 'AAA1@BBB1.com.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정수 인코딩"
      ],
      "metadata": {
        "id": "tWUdLA1eanaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_seq_tr[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBwkz7-nMrCB",
        "outputId": "b3213565-6c11-4dda-9c89-a84f512062fb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['그',\n",
              "  '말',\n",
              "  '들다',\n",
              "  '기쁘다',\n",
              "  '저희',\n",
              "  '거래',\n",
              "  '하다',\n",
              "  '것',\n",
              "  '고려',\n",
              "  '하다',\n",
              "  '주다',\n",
              "  '하다',\n",
              "  '<EOS>'],\n",
              " ['확실하다', '생각', '있다', '몇', '가지', '여쭈다', '보고', '싶다', '게', '있다', '<EOS>']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞서 toekn-index dictionary로 정리한 것을 이용해서 각각의 토큰들을 정수인코딩을 진행해봅니다.\n",
        "# 이 과정에서 유의할 점은, 기존의 구현 코드에서 여러개의 for loop을 사용했습니다.\n",
        "# 이보다 빨리 진행하기 위해 어떻게 코딩할 수 있을까요?\n",
        "# 시간이 충분하시다면 for loop을 그대로 이용하셔도 좋습니다만, 다른 방법도 고민하셔도 좋습니다.\n",
        "# hint: Pandas에서 apply와 비슷한 것들을 이용해보면 어떨까요?\n",
        "\n",
        "# encoder의 입력값 정수 인코딩 진행\n",
        "\"\"\"\n",
        "\n",
        "encoder_input = []\n",
        "\n",
        "# 1개의 문장\n",
        "for line in src_seq_tr:\n",
        "  encoded_line = []\n",
        "  # 각 줄에서 1개의 알파벳별로 처리. 앞서서 동일한 방식으로 tokenization을 했기 때문!\n",
        "  for char in line:\n",
        "    # 각 알파벳을 정수로 바꾸어야합니다. 왜 하필 정수형이냐에 대해선 이후에 있을 Embedding과 관련 있습니다.\n",
        "    # 우선 각 알파벳을 숫자로 바꿔줍니다.\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  # 위에서 사용한 index도 정수형이긴한데, 결국 torch.Tensor를 사용해야 하고, Tensor에서 정수형에 해당하는 type이 LongTensor이기 때문에\n",
        "  # .long()을 이용하여 정수형으로 만들어 줍니다.\n",
        "  encoder_input.append(torch.Tensor(encoded_line).long())\n",
        "print('source 문장의 정수 인코딩 :\\n',encoder_input[:5], '\\n')\n",
        "\"\"\"\n",
        "encoder_input = list(map(lambda line: torch.Tensor(list(map(lambda char: src_to_index[char], line))).long(), src_seq_tr))\n",
        "print('source 문장의 정수 인코딩 :\\n',encoder_input[:5], '\\n')"
      ],
      "metadata": {
        "id": "ocvHdAzp0B3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a150b119-384f-4674-d92f-ee52fd32b201"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 정수 인코딩 :\n",
            " [tensor([ 651, 1599, 1343,  761, 4153,  303, 5448,  359,  453, 5448, 4426, 5448,\n",
            "           1]), tensor([5679, 2530, 3994, 1713,  188, 3347, 2101, 3046,  362, 3994,    1]), tensor([3445, 2636,  131, 4477,  131,  462,  261, 1401, 1319, 1047, 5032, 3994,\n",
            "           1]), tensor([ 651, 1599, 5448, 4153,  651, 3093, 1269,  359, 3787,    1]), tensor([4413, 2783, 3241,  170,    1])] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 우선 decoder에서 사용하는 문장에 대해 정수인코딩 진행\n",
        "\"\"\"\n",
        "decoder_input = []\n",
        "# 여기서 line은 문자열에 해당합니다. \n",
        "for line in tar_seq_tr:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(tar_to_index[char])\n",
        "  # 현재 데이터 상 문장 맨 마지막에는 <EOS>가 들어가 있는데, decoder를 학습할 때 <EOS>를 넣지 않으니 마지막의 값을 pop하여 제외합니다.\n",
        "  encoded_line.pop(-1)\n",
        "\n",
        "  # 여기서 .long()은 정수 인코딩된 문장들의 type을 정하는 것으로, 이후에 Embedding layer를 사용할 때 해당 타입을 사용해야하기 때문에 사용한 것입니다.\n",
        "  decoder_input.append(torch.Tensor(encoded_line).long())  \n",
        "print('target 문장의 정수 인코딩 :\\n',decoder_input[:5],'\\n')\n",
        "\"\"\"\n",
        "decoder_input = list(map(lambda line: torch.Tensor(list(map(lambda char: tar_to_index[char],line))[:-1]).long(),tar_seq_tr))\n",
        "print('target 문장의 정수 인코딩 :\\n',decoder_input[:5],'\\n')"
      ],
      "metadata": {
        "id": "l1wFXKiAPfyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760a6e32-6949-4aba-a76e-c24f499fc171"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장의 정수 인코딩 :\n",
            " [tensor([   2,  328, 4033, 3238, 6350, 3388, 6279, 1016,  328, 3455, 6897, 2467,\n",
            "        1980, 2481, 1519, 6831, 6586]), tensor([   2,  328, 4033, 2277, 6304,  786, 3770, 1524,  328, 3377, 5836, 5087,\n",
            "        6350, 1127, 6897]), tensor([   2,  339, 6354, 5488, 6856, 4472, 3567, 2775, 3028, 2921, 3372, 2613,\n",
            "         782, 1621, 2479, 4508, 1434]), tensor([   2,  751, 6897, 6233, 6284, 6753, 3968, 6171, 1595, 4445, 6282, 1716]), tensor([   2,  492, 3482,  786, 3085, 6146])] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다만 decoder의 출력값은 <SOS>들어가면 안되니 첫번째 토큰은 빼주기\n",
        "\"\"\"\n",
        "decoder_target = []\n",
        "for line in tar_seq_tr:\n",
        "  # 여기서 timestep은 시퀀스 상 몇번째 값인지 알려주는 값입니다.\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    # Decoder가 출력하는 값에서 문장의 시작을 알리는 값(SOS)가 들어가면 안됩니다.\n",
        "    # 반면 현재 데이터는 SOS로 시작하는 형태입니다. \n",
        "    # 그래서 시퀀스에서 0번째를 제외한 경우만 추가를 하게 된다면 적절히 제외될 것입니다. \n",
        "    if timestep > 0:\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "    timestep = timestep + 1\n",
        "  \n",
        "  decoder_target.append(torch.Tensor(encoded_line).long())\n",
        "print('target 문장 레이블의 정수 인코딩 :\\n',decoder_target[:5],'\\n')\n",
        "\"\"\"\n",
        "decoder_target = list(map(lambda line: torch.Tensor(list(map(lambda char: tar_to_index[char],line))[1:]).long(),tar_seq_tr))\n",
        "print('target 문장 레이블의 정수 인코딩 :\\n',decoder_target[:5],'\\n')"
      ],
      "metadata": {
        "id": "3377QUWVPgXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12731b72-12bb-48b7-97b6-67f0753d4463"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장 레이블의 정수 인코딩 :\n",
            " [tensor([ 328, 4033, 3238, 6350, 3388, 6279, 1016,  328, 3455, 6897, 2467, 1980,\n",
            "        2481, 1519, 6831, 6586,    1]), tensor([ 328, 4033, 2277, 6304,  786, 3770, 1524,  328, 3377, 5836, 5087, 6350,\n",
            "        1127, 6897,    1]), tensor([ 339, 6354, 5488, 6856, 4472, 3567, 2775, 3028, 2921, 3372, 2613,  782,\n",
            "        1621, 2479, 4508, 1434,    1]), tensor([ 751, 6897, 6233, 6284, 6753, 3968, 6171, 1595, 4445, 6282, 1716,    1]), tensor([ 492, 3482,  786, 3085, 6146,    1])] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fT3x1SL_l1pY"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding"
      ],
      "metadata": {
        "id": "ibj8DeCqbvZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sSNmdbEwuQR5"
      },
      "outputs": [],
      "source": [
        "# 현재 길이가 제각각인 정수화된 문장이 있습니다. padding을 통해 길이를 맞춰봅시다\n",
        "# 주의사항: 여기에 사용된 값을은 정수일까요?\n",
        "\n",
        "\n",
        "batch_first = True #True로 해야 문장개수 - 길이 순서로 됨.\n",
        "\n",
        "encoder_input_tr = pad_sequence(encoder_input, batch_first = batch_first).long()\n",
        "decoder_input_tr = pad_sequence(decoder_input, batch_first = batch_first).long()\n",
        "decoder_target_tr = pad_sequence(decoder_target, batch_first = batch_first).long()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ_AHRQPmfZX"
      },
      "source": [
        "## Train data\n",
        "\n",
        "tuple type으로,  (encoder_input, decoder_input, decoder_target)의 순서를 가지게 됩니다. 이는 tuple assignment를 이용하려고 하는 것이니 자유롭게 사용하셔도 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YXqi5dV-mjQD"
      },
      "outputs": [],
      "source": [
        "train_data = tuple([encoder_input_tr, decoder_input_tr, decoder_target_tr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXhsP4O3mhih"
      },
      "source": [
        "## Eval data 33:00~\n",
        "\n",
        "지금까지 진행한 것은 학습 데이터에 대한 전처리입니다.\n",
        "\n",
        "그런데 말입니다, 과연 평가 데이터는 학습데이터랑 동일한 형태일까요?\n",
        "\n",
        "사용하는 단어도 동일할까요?\n",
        "\n",
        "게다가 실제 데이터라면 문장 속에 이메일이나, 전화번호등 다른 것들로 대체해야할 게 있지 않을까요?\n",
        "\n",
        "참으로 고민할 게 많습니다. 이 모든 것들을 고려하면 좋겠지만, 현재 과제에서는 학습 데이터의 단어 집합에는 없는데 평가 데이터에서 등장하는 단어들은 어떻게 처리할지 한번 고민해봅시다.\n",
        "\n",
        "**핵심 TODO**:만약에 본 적이 없는 token이 나온다면 어떻게 될까요?\n",
        "\n",
        "--> Out of Vocabulary !  =지금까지 단어 집합에 없던 아이들!<br>\n",
        "\n",
        "이를 한번에 처리해주는 토큰으로 \\<UNK\\>(=unknown token) 을 사용\n",
        "\n",
        "EX)\n",
        "\n",
        "train data : \"나는 밥을 먹는다.\"<br>\n",
        "\\>> [\"나\", \"밥\", \"먹다\"]<br>\n",
        "\\>> [\\<SOS\\>, 나, 밥, 먹다, \\<EOS\\>] <BR>\n",
        "\\>> {\\<SOS\\>:0, \\<EOS\\>:1, \\<UNK\\>: 2, 나:3, 밥:4, 먹다:5}  <bR>\n",
        "\\>> [0, 3, 4, 5, 1] <BR>\n",
        "\n",
        "val data: \"나는 고기를 먹는다\"<br>\n",
        "\\>> ['나', '고기' '먹다']<BR>\n",
        "\\>> [\\<SOS\\>, 나, \\<UNK\\>, 먹다, \\<EOS\\>] <BR>\n",
        "\\>> [0, 3, 2, 5, 1] <BR>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_ZlcbYvagQD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_seq_val = []\n",
        "tar_seq_val = []\n",
        "\n",
        "\n",
        "for raw_val_dat in tqdm(raw_val_data):\n",
        "  # 문장별 tokenization\n",
        "  src_tmp = CustomTokenizer(raw_tr_dat['ko'])\n",
        "  tar_tmp = CustomTokenizer(raw_tr_dat['en'])\n",
        "\n",
        "  # 입력 시퀀스에서 문장의 끝을 알리는 <EOS> 토큰 추가\n",
        "  # 출력 시퀀스에서 시작과 끝을 알리는 <SOS>, <EOS> 토큰 추가\n",
        "  src_tmp.append('<EOS>')\n",
        "  tar_tmp.append('<EOS>')\n",
        "  tar_tmp.insert(0, '<SOS>')\n",
        "\n",
        "  # 처음보는 단어들은 일단 모르는 단어(OOV)로 표시해놓기  \n",
        "  # 해당 과정에서는 지금 얻은 toekn들(src_tmp와 tar_tmp)들 중에서 학습 데이터의 단어 집합(src_vocab과 tar_vocab)에 없는 단어들을 찾아야 합니다.\n",
        "  # 즉 위의 예시에서 \"고기\"에 해당하는 token을 찾아야 하고, 이를 list로 저장해봅시다.\n",
        "  src_oov = [char for char in src_tmp if char not in src_vocab]\n",
        "  tar_oov = [char for char in tar_tmp if char not in tar_vocab]\n",
        "\n",
        "  # OOV들은 <UNK>로 바꾸는 과정입니다.\n",
        "  # 지금 문장을 tokenization되어 있고, 앞서 구한 모르는 단어(OOV)들의 리스트(src_oov와 tar_oov)가 있는 상황에서\n",
        "  # 해당 리스트에 속한 토큰들은 <UNK>토큰으로 바꿔주는 것을 구현하는 파트입니다.\n",
        "  # 위의 예시에서 본다면 [<SOS>, 나, 고기, 먹다, <EOS>]를 [<SOS>, 나, <UNK>, 먹다, <EOS>]로 만들어주는 과정입니다.\n",
        "  src_tmp = [char if char not in src_oov else '<UNK>' for char in src_tmp]\n",
        "  tar_tmp = [char if char not in tar_oov else '<UNK>' for char in tar_tmp]\n",
        "\n",
        "  # tokenization 끝난 문장 보관\n",
        "  src_seq_val.append(src_tmp)\n",
        "  tar_seq_val.append(tar_tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvlFP0Q94rU3",
        "outputId": "871ce688-0f28-43f6-cc5b-468d933ba1c9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:11<00:00, 88.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar_seq_val[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7x2S0t08dfe",
        "outputId": "b5a81598-dc17-4428-a6ed-3daea680bf02"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<SOS>',\n",
              " 'Good',\n",
              " 'afternoon',\n",
              " 'I',\n",
              " 'm',\n",
              " 'looking',\n",
              " 'for',\n",
              " 'an',\n",
              " 'interior',\n",
              " 'designer',\n",
              " 'for',\n",
              " 'my',\n",
              " 'company',\n",
              " 's',\n",
              " 'new',\n",
              " 'South',\n",
              " 'Korean',\n",
              " 'offices',\n",
              " '<EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 샘플을 보면 생각보다 너무 많은 단어들이 UNK로 바뀌었습니다. 이게 과연 성능에 어떤 영향을 끼칠까요? 이를 방지할 수 있는 대책은 무엇일까요?\n",
        "\n",
        "정답은 없습니다. 자유롭게 고민해보셔도 좋을 것 같습니다."
      ],
      "metadata": {
        "id": "70nzuKIPf3nX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UNK 토큰 추가 및 단어집합, token-index 업데이트"
      ],
      "metadata": {
        "id": "KoH1M8GofxwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UNK가 추가되면서 vocab과 index도 업데이트를 해야합니다.\n",
        "# 즉 지금 방식으로 처리한다면, 지금 단어 집합에는 <UNK>라는 토큰이 없습니다.\n",
        "# 그래서 UNK 토큰에도 정수를 할당해줘야 합니다.\n",
        "# 지금 0은 padding에서 사용하고 있으니 아래의 과정은 마지막에 <UNK>를 추가해보는 것입니다."
      ],
      "metadata": {
        "id": "lE3iIu_W8-78"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 시퀀스의 마지막 토큰과 정수인코딩값 확인\n",
        "list(src_to_index.items())[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRl3l4bE9cVh",
        "outputId": "5368032e-19c6-4527-ef06-e30de6488735"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('힘쓰다', 5767)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 입력 시퀀스에 사용된 token들의 개수 확인\n",
        "len(src_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRuj2FNmgfA3",
        "outputId": "bd7b56ad-233d-4bb7-9184-c48d74e2c594"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5767"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 우리는 마지막 토큰 뒤에 UNK 토큰을 추가해봅시다\n",
        "# 이 때 입력 시퀀스(src_to_index)와 출력시퀀스(tar_to_index)에 모두 사용해줘야 합니다.\n",
        "src_to_index[\"<UNK>\"] = len(src_vocab) + 1\n",
        "tar_to_index[\"<UNK>\"] = len(tar_vocab) + 1"
      ],
      "metadata": {
        "id": "2hQsCc5i9aw2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력시퀀스의 단어집합 확인\n",
        "print(list(tar_to_index.items())[:5])\n",
        "print(list(tar_to_index.items())[-1:-5:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09pOS9MtaUVJ",
        "outputId": "6dc5c8dc-b237-48cd-a356-754f59a8eff2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<EOS>', 1), ('<SOS>', 2), ('A', 3), ('AAA', 4), ('AAA1@BBB1.com.', 5)]\n",
            "[('<UNK>', 6909), ('zoom', 6908), ('zones', 6907), ('zero', 6906)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력시퀀스의 단어집합 확인\n",
        "print(list(src_to_index.items())[:5])\n",
        "print(list(src_to_index.items())[-1:-5:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZqYpbTe-AK1",
        "outputId": "8ab571f8-6ece-4b7d-dd4a-85ed5e923c8f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<EOS>', 1), ('A', 2), ('AAA', 3), ('AAA1@BBB1.com', 4), ('AAA@BBB.com', 5)]\n",
            "[('<UNK>', 5768), ('힘쓰다', 5767), ('힘들다', 5766), ('힘', 5765)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정수 인코딩"
      ],
      "metadata": {
        "id": "-E5zRRZuhQa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 데이터에 대해서  정수 인코딩을 진행해주세요!\n",
        "# 이 과정에서 중요한 점은 우린 학습데이터만 가지고 있으니 학습 데이터에서 사용했던 toekn-index로 인코딩을 진행해야 합니다!\n",
        "# 참고 : 어떻게 하면 효율적 혹은 빠르게 할까요?\n",
        "\n",
        "# 앞서 toekn-index dictionary로 정리한 것을 이용해서 각각의 토큰들을 정수인코딩을 진행해봅니다.\n",
        "# 이 과정에서 유의할 점은, 기존의 구현 코드에서 여러개의 for loop을 사용했습니다.\n",
        "# 이보다 빨리 진행하기 위해 어떻게 코딩할 수 있을까요?\n",
        "# 시간이 충분하시다면 for loop을 그대로 이용하셔도 좋습니다만, 다른 방법도 고민하셔도 좋습니다.\n",
        "# hint: Pandas에서 apply와 비슷한 것들을 이용해보면 어떨까요?\n",
        "\n",
        "# encoder의 입력값 정수 인코딩 진행\n",
        "\n",
        "encoder_input = []\n",
        "\n",
        "# 1개의 문장\n",
        "for line in src_seq_val:\n",
        "  encoded_line = []\n",
        "  # 각 줄에서 1개의 알파벳별로 처리. 앞서서 동일한 방식으로 tokenization을 했기 때문!\n",
        "  for char in line:\n",
        "    # 각 알파벳을 정수로 바꾸어야합니다. 왜 하필 정수형이냐에 대해선 이후에 있을 Embedding과 관련 있습니다.\n",
        "    # 우선 각 알파벳을 숫자로 바꿔줍니다.\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  # 위에서 사용한 index도 정수형이긴한데, 결국 torch.Tensor를 사용해야 하고, Tensor에서 정수형에 해당하는 type이 LongTensor이기 때문에\n",
        "  # .long()을 이용하여 정수형으로 만들어 줍니다.\n",
        "  encoder_input.append(torch.Tensor(encoded_line).long())\n",
        "print('source 문장의 정수 인코딩 :\\n',encoder_input[:5], '\\n')\n",
        "\n",
        "# 우선 decoder에서 사용하는 문장에 대해 정수인코딩 진행\n",
        "decoder_input = []\n",
        "# 여기서 line은 문자열에 해당합니다. \n",
        "for line in tar_seq_val:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(tar_to_index[char])\n",
        "  # 현재 데이터 상 문장 맨 마지막에는 <EOS>가 들어가 있는데, decoder를 학습할 때 <EOS>를 넣지 않으니 마지막의 값을 pop하여 제외합니다.\n",
        "  encoded_line.pop(-1)\n",
        "\n",
        "  # 여기서 .long()은 정수 인코딩된 문장들의 type을 정하는 것으로, 이후에 Embedding layer를 사용할 때 해당 타입을 사용해야하기 때문에 사용한 것입니다.\n",
        "  decoder_input.append(torch.Tensor(encoded_line).long())  \n",
        "print('target 문장의 정수 인코딩 :\\n',decoder_input[:5],'\\n')\n",
        "\n",
        "\n",
        "# 다만 decoder의 출력값은 <SOS>들어가면 안되니 첫번째 토큰은 빼주기\n",
        "decoder_target = []\n",
        "for line in tar_seq_val:\n",
        "  # 여기서 timestep은 시퀀스 상 몇번째 값인지 알려주는 값입니다.\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    # Decoder가 출력하는 값에서 문장의 시작을 알리는 값(SOS)가 들어가면 안됩니다.\n",
        "    # 반면 현재 데이터는 SOS로 시작하는 형태입니다. \n",
        "    # 그래서 시퀀스에서 0번째를 제외한 경우만 추가를 하게 된다면 적절히 제외될 것입니다. \n",
        "    if timestep > 0:\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "    timestep = timestep + 1\n",
        "  \n",
        "  decoder_target.append(torch.Tensor(encoded_line).long())\n",
        "print('target 문장 레이블의 정수 인코딩 :\\n',decoder_target[:5],'\\n')\n"
      ],
      "metadata": {
        "id": "LHRGJgfs-axo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10be8ac-59bc-4540-908a-cff938008f92"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 정수 인코딩 :\n",
            " [tensor([3127, 4153, 5486, 3994, 4153, 5707, 2513, 2405, 3660, 3912, 1368, 4697,\n",
            "        3994,    1]), tensor([3127, 4153, 5486, 3994, 4153, 5707, 2513, 2405, 3660, 3912, 1368, 4697,\n",
            "        3994,    1]), tensor([3127, 4153, 5486, 3994, 4153, 5707, 2513, 2405, 3660, 3912, 1368, 4697,\n",
            "        3994,    1]), tensor([3127, 4153, 5486, 3994, 4153, 5707, 2513, 2405, 3660, 3912, 1368, 4697,\n",
            "        3994,    1]), tensor([3127, 4153, 5486, 3994, 4153, 5707, 2513, 2405, 3660, 3912, 1368, 4697,\n",
            "        3994,    1])] \n",
            "\n",
            "target 문장의 정수 인코딩 :\n",
            " [tensor([   2,  293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317,\n",
            "        1873, 5488, 4359,  624,  392, 4456]), tensor([   2,  293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317,\n",
            "        1873, 5488, 4359,  624,  392, 4456]), tensor([   2,  293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317,\n",
            "        1873, 5488, 4359,  624,  392, 4456]), tensor([   2,  293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317,\n",
            "        1873, 5488, 4359,  624,  392, 4456]), tensor([   2,  293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317,\n",
            "        1873, 5488, 4359,  624,  392, 4456])] \n",
            "\n",
            "target 문장 레이블의 정수 인코딩 :\n",
            " [tensor([ 293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317, 1873,\n",
            "        5488, 4359,  624,  392, 4456,    1]), tensor([ 293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317, 1873,\n",
            "        5488, 4359,  624,  392, 4456,    1]), tensor([ 293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317, 1873,\n",
            "        5488, 4359,  624,  392, 4456,    1]), tensor([ 293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317, 1873,\n",
            "        5488, 4359,  624,  392, 4456,    1]), tensor([ 293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317, 1873,\n",
            "        5488, 4359,  624,  392, 4456,    1])] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding"
      ],
      "metadata": {
        "id": "ws8RA6UThh0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 주의사항: 여기에 사용된 값을은 정수일까요?\n",
        "encoder_input_val = pad_sequence(encoder_input, batch_first = batch_first).long()\n",
        "decoder_input_val = pad_sequence(decoder_input, batch_first = batch_first).long()\n",
        "decoder_target_val = pad_sequence(decoder_target, batch_first = batch_first).long()"
      ],
      "metadata": {
        "id": "4Qc_bb02-s6_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "E7DOj62GnAfX"
      },
      "outputs": [],
      "source": [
        "val_data = tuple([encoder_input_val, decoder_input_val, decoder_target_val])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlZl7q5cxscM"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "실습코드에서 사용한 것과 동일한 구조입니다! \n",
        "\n",
        "사실 앞서 처리가 진행되었던 모든 과정은 Dataset에서 __get_item__ 함수 내에서 처리해서 값을 리턴할 수도 있습니다.\n",
        "\n",
        "다만 설명을 위해 이번 과제에서는 과정을 단계별로 설명 드렸습니다. 추후에 진행하실 때엔 __get_item__에서 구현해보셔도 좋을 것 같아요!\n",
        "\n",
        "그리고 일부 단계의 경우 임의로 처리된 것들이 있습니다.(tokenization부터 stopwords 등등) 가령 이메일, 전화번호와 같은 단어들은 \\<UNK\\>처럼 새로운 토큰을 이용해서 처리할 수도 있으며 목적에 따라서 다른 tokenziation을 사용할 수 있습니다.\n",
        "\n",
        "**(참고)**\n",
        "\n",
        " __get_item__말고 사전에 전처리를 다한 상태로 사용할 경우 사실 사용할 모든 데이터를 메모리에 올려놓고 사용하는 것과 같습니다.(변수에 할당되어 있으니)\n",
        "\n",
        "그런데 우리가 데이터가 매매매매매우 많아진다면, 메모리가 부족해질 수도 있지 않을까요? 그렇기 때문에 때에 따라 data를 필요할 때 전처리를 하고 반환하기도 합니다. 여기서 data가 필요할때란 결국 __get_item__을 호출할 때가 될 것입니다.\n",
        "\n",
        "정리하자면, 꼭 모든 데이터를 한번에 다 전처리해놓도 준비해놓지 않고도, 필요할 때 마다(get_item이 호출될 때마다) 전처리해서 결과를 전달하는 방법도 있습니다.\n",
        "\n",
        "다만 해당 과제에서는 Seq2Seq에 익숙해지는 것을 목표로 하기에 이러한 점만 알고 가셔도 충분하기도 하고, 오히려 사전에 다 처리해놓는 현재 방식이 더 효율적일 수도 있습니다. 그렇기 때문에 이 점만 알고 가셔도 좋을 것 같습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "j5lj6ZOPxpcj"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xc7ZqjGmx1dk"
      },
      "outputs": [],
      "source": [
        "class textDataset(Dataset):\n",
        "  def __init__(self, data, batch_first=True):\n",
        "    super(textDataset, self).__init__()\n",
        "    # tuple asgginment를 활용한다면 굳이 argument로 모든 데이터를 받지 않아도 됩니다!\n",
        "    enc_inp, dec_inp, dec_out = data\n",
        "\n",
        "    # 내부에서 사용할 변수들 정리하는 것으로, 모든 데이터가 torch.LongTensor로 정리된 값들이 저장됩니다.\n",
        "    self.enc_inp = enc_inp\n",
        "    self.batch_first= batch_first\n",
        "    self.dec_inp = dec_inp\n",
        "    self.dec_out = dec_out\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "     return self.enc_inp[idx], self.dec_inp[idx],self.dec_out[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.enc_inp.size(int(~self.batch_first))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Z30_EO0uxrgH"
      },
      "outputs": [],
      "source": [
        "train_dataset = textDataset(train_data, batch_first=batch_first)\n",
        "val_dataset = textDataset(val_data, batch_first=batch_first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_AqR38AoB5n",
        "outputId": "845decab-61ad-4f94-db61-653a3efcbe11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3127, 4153, 5486, 3994, 4153, 5707, 2513, 2405, 3660, 3912, 1368, 4697,\n",
              "         3994,    1]),\n",
              " tensor([   2,  293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317,\n",
              "         1873, 5488, 4359,  624,  392, 4456]),\n",
              " tensor([ 293,  927,  328, 4033, 4005, 3085, 1009, 3712, 2331, 3085, 4317, 1873,\n",
              "         5488, 4359,  624,  392, 4456,    1]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "val_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIDKAtrLe99M",
        "outputId": "78434698-4a00-4e69-e45d-76b3806318ba"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYq6eGm0qaOh"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ce3NfbA2qfSV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcThBf_DqbuT"
      },
      "source": [
        "## Encoder\n",
        "\n",
        "본 모델에서는 LSTM를 기본 단위로 가지는 Seq2Seq 모델을 구성할 것  \n",
        "(batch_size, seq_len, input_size) 순서.  \n",
        "batch_size : batch_size만큼의 문장이 들어오는 것, len([seq1, seq2,...]).  \n",
        "seq_len : 문장 길이. len([token1, token2,...])  \n",
        "input size : layer의 input은 정수인코딩이 아니라 embedding 벡터, embedding 차원을 이야기함.  \n",
        "\n",
        "참고 [레퍼런스](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "A719R9uZqZG2"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_size, hid_size, tok_size, bat_first=True, num_lay=1, bidirect=False):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hid_size\n",
        "\n",
        "    self.embedding = nn.Embedding(tok_size, in_size)\n",
        "\n",
        "    self.num_layers = num_lay\n",
        "\n",
        "    self.num_directional = 2 if bidirect else 1\n",
        "\n",
        "    self.batch_first = bat_first\n",
        "    self.lstm = nn.LSTM(in_size, \n",
        "                        hid_size, \n",
        "                        num_layers = num_lay,\n",
        "                        batch_first = bat_first,\n",
        "                        bidirectional=bidirect)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    \"\"\"\n",
        "    x: (batch_size, seq_len)\n",
        "    hidden: (batch_size, seq_len, hidden_size)\n",
        "    \"\"\"\n",
        "\n",
        "    # emb: (batch_size, seq_len, input_size)\n",
        "    emb = self.embedding(x)\n",
        "\n",
        "    # out : (batch_size, seq_len, hidden_size)\n",
        "    # hidden: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "    out, hidden = self.lstm(emb, hidden)\n",
        "    return out, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu4CMe_5JN2I"
      },
      "source": [
        "## Decoder\n",
        "\n",
        "decoder의 hidden이 아닌 out으로 예측하고, 그 값 하나를 이용해서 다음 값 계산에 사용하기 때문에 seq_len =1이 된다.  \n",
        "\n",
        "task가 조금 다르다. 맥락을 알려줬을 때 위치별로 적절한 단어들을 알려주게 되는 것. 순차적으로 알려주게 됨. 임베딩 하나 넣고 - 하나 알고 - 하나 넣고 - 하나 알고. 한 번에 긴 문장이 들어가는 것이 아니라 한 단어 넣고 한 단어 빼고. output을 입력값으로 사용한다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Wc1u4z_k4RKp"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_size, hid_size, tok_size, bat_first=True, num_lay=1, bidirect=False):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.hidden_size = hid_size\n",
        "    self.embedding = nn.Embedding(tok_size, in_size)\n",
        "    self.num_layers = num_lay\n",
        "    self.num_directional = 2 if bidirect else 1\n",
        "    self.batch_first = bat_first\n",
        "    self.lstm = nn.LSTM(in_size,\n",
        "                        hid_size,\n",
        "                        num_layers = num_lay,\n",
        "                        batch_first = bat_first,\n",
        "                        bidirectional = bidirect)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(hidden_size, tok_size)\n",
        "    \n",
        "  def forward(self, x, hidden):\n",
        "    \"\"\"\n",
        "    x: (batch_size, seq_len=1)\n",
        "    hidden: (num_directional*num_layers, batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "\n",
        "    # emb: (batch_size, seq_len=1, input_size)\n",
        "    emb = self.embedding(x[:, 0]).unsqueeze(1)\n",
        "    # x[:0] : (batch_size, )\n",
        "    # embedding(x[:,0]) : (batchsize, input_size)\n",
        "    # 그런데 두 번째에 seq_len이 1이 되어야 잘 돌아간다\n",
        "\n",
        "    out = self.relu(emb)\n",
        "\n",
        "\n",
        "    # out : (batch_size, seq_len=1, hidden_size)\n",
        "    # hidden: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "    out, hidden = self.lstm(out, hidden)\n",
        "\n",
        "    #out.squeeze(1) : (batch_size, hidden_size)\n",
        "    \n",
        "    out = self.fc1(out.squeeze(1))\n",
        "    # 결국에는 다음 단어를 예측을 해야 함.\n",
        "    # LSTM이 지금까지 거쳐온 sequence의 정보를 가지고 있는 vector를 반환하는데, (이 hidden state의 정보를)\n",
        "    # 토큰의 개수별로 매핑을 해줘서 \n",
        "    # 토큰별로 확률을 계산을 해야 - 뭐가 등장하는지 이야기할 수 있음.\n",
        "    return out, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "X1qHG3DT4dSH"
      },
      "outputs": [],
      "source": [
        "def init_hidden(self, x):\n",
        "  \"\"\"\n",
        "  레퍼런스 참고\n",
        "  when batch_first=True (num_directional*num_layers, batch_size, hidden_size)\n",
        "  \"\"\"\n",
        "  batch_size = x.size(0) if self.batch_first else x.size(1)\n",
        "  h0 = torch.zeros(self.num_layers*self.num_directional, batch_size, self.hidden_size).to(device)\n",
        "  c0 = torch.zeros(self.num_layers*self.num_directional, batch_size, self.hidden_size).to(device)\n",
        "  return h0, c0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toqV7UDhPqN6"
      },
      "source": [
        "## Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "YIzlUzPlJK3W"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, enc, dec):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    assert enc.hidden_size == dec.hidden_size\n",
        "    assert enc.num_layers == dec.num_layers\n",
        "\n",
        "    self.encoder = enc\n",
        "    self.decoder = dec\n",
        "\n",
        "  def forward(self, enc_inp, dec_inp, use_teacher_force=True):\n",
        "    \"\"\"\n",
        "    enc_inp : (batch_size, enc_seq_len)\n",
        "    dec_inp : (batch_size, dec_seq_len)\n",
        "    \"\"\"\n",
        "\n",
        "    # 어떤 값을 써야할까요?\n",
        "    batch_size = enc_inp.size(0)\n",
        "    enc_seq_len = enc_inp.size(1)\n",
        "    dec_seq_len = dec_inp.size(1)\n",
        "\n",
        "    token_size =  self.decoder.fc1.out_features\n",
        "    #output feature가 결국 token size가 됨.\n",
        "\n",
        "    # decoder 확률(점수) 예측값 저장\n",
        "    # outputs: (batch_size, seq_len, token_size)\n",
        "    outputs = torch.zeros(batch_size, dec_seq_len, token_size)\n",
        "\n",
        "    # Step 0: Encoder의 forward에 필요한 초기 hidden, cell state 계산\n",
        "    enc_init_hidden = init_hidden(self.encoder, enc_inp)\n",
        "\n",
        "    # Step 1: Encoder를 이용하여 context 벡터 생성\n",
        "    # 참고: context 벡터는 output가 아님 - hidden임!!\n",
        "    _, context = self.encoder(enc_inp, enc_init_hidden)\n",
        "\n",
        "    # Step 2: Decoder의 초기 입력값을 먼저 할당\n",
        "    # 참고: 첫 입력값으로 decoder의 입력값을 이용할 수 있음 : 첫번째 값!!!! <SOS>..\n",
        "    # 주의할 사항 \n",
        "    #    - (batch_size, dec_seq_len)의 차원을 맞추기 \n",
        "    #    - 이렇게 하는 이유는 decoder에서 forward에 들어가야하는 input의 구조(차원)이 정해져 있기 때문\n",
        "    dec_inp_t = dec_inp[:, 0].unsqueeze(-1) #unsqueeze 안하면 1차원됨\n",
        "\n",
        "    # Step 3: Decoder를 이용하여 하나하나 계산(예측)하고, 입력값 업데이트하기\n",
        "    # 주의사항\n",
        "    #    - Encoder의 최종 리턴한 hidden state가 context 벡터고 이게 decoder에서 init_hidden에 해당\n",
        "    #    - 앞서 첫 입력값은 직접 확인했으니 다음 입력값부터 하기에 range는 1부터 시작하는 구조로?!\n",
        "    dec_hidden = context\n",
        "    for t in range(1, dec_seq_len):\n",
        "      out, dec_hidden = self.decoder(dec_inp_t, dec_hidden)\n",
        "      # out : 각 step별 결과물을 가지게 됨\n",
        "      outputs[:, t, :] = out\n",
        "\n",
        "      if use_teacher_force:\n",
        "        # 주의사항 : 차원 맞추기 \n",
        "        # 해당 경우 decoder의 입력값을 가져다가 사용해야 합\n",
        "        dec_inp_t = dec_inp[:, t].unsqueeze(-1)\n",
        "      else:\n",
        "        # 주의사항 : 차원 맞추기 \n",
        "        # 해당 경우 이번 시점의 예측값을 다음 시점의 입력값으로 해야함\n",
        "        dec_inp_t = out.argmax(1, keepdim=True)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSfBWsX0Po1I"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "2VSNdoUUPoMS"
      },
      "outputs": [],
      "source": [
        "# padding에 해당하는 token도 고려하기\n",
        "enc_token_size = len(src_to_index)+1\n",
        "dec_token_size = len(tar_to_index)+1\n",
        "\n",
        "# Hyper-parameter!!\n",
        "# RAM 메모리 이슈로 다운 되는 경우 때문에 줄였습니다.\n",
        "input_size = 4\n",
        "hidden_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "edfUD7SOP6pM"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(input_size, hidden_size, enc_token_size)\n",
        "decoder = Decoder(input_size, hidden_size, dec_token_size)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3wAllAwQQbc"
      },
      "source": [
        "## 생략된 내용들\n",
        "\n",
        "모델 생성하는 과정에서 초기값이나 등등 부수적인 부분들은 현재 과제 코드상에서 생략되었습니다. 모델 개선에 관심있으신 분들은 수행하셔도 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "nNlOosmzQP4W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofoXIctbQigu"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "NUnTP6xbQlV1"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, cri):\n",
        "  model.train()\n",
        "  loss_ep = 0\n",
        "\n",
        "  for enc_input, dec_input, dec_target in loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # output: (batch_size, seq_len, token_size)\n",
        "    output =  model(enc_input.to(device), dec_input.to(device), use_teacher_force=True)\n",
        "    token_size = output.size(-1)\n",
        "\n",
        "    # 지금 [문장, 문장, ...] 구조에서 문장들을 그냥 순서대로 이어 붙인 것\n",
        "    # loss 계산을 위한 조정\n",
        "    # output : (batch_size * seq_len, toekn_size)\n",
        "    output = output.view(-1, token_size)\n",
        "\n",
        "    # 위와 동일한 방식으로 label 값도 조정\n",
        "    # dec_target: (batch_size, seq_len)\n",
        "    # target (batch_size*seq_len,)\n",
        "    target = dec_target.view(-1)\n",
        "\n",
        "    loss = cri(output, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_ep += loss.item()\n",
        "  return loss_ep/len(loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-g8kExh9V87"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "OM_5gT6uCXMh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "y6mXBkq69VSW"
      },
      "outputs": [],
      "source": [
        "def val(model, loader, cri):\n",
        "  # 예측값도 확인하기 위해 예측값 저장하는 값\n",
        "  result = torch.Tensor()\n",
        "\n",
        "  model.eval()\n",
        "  loss_ep = 0\n",
        "  with torch.no_grad():\n",
        "    for enc_input, dec_input, dec_target in loader:\n",
        "      # 여기서 output은 en/decoder가 아닌 seq2seq의 결과값\n",
        "      # output: (batch_size, seq_len, token_size)\n",
        "      output = model(enc_input.to(device), dec_input.to(device), use_teacher_force=False)\n",
        "\n",
        "      # 평가할 땐 loss 말고 예측값도 반환하기 위해 저장\n",
        "      # decode_idx = 해당 시점에서 예측한 token의 정수인코딩값. \n",
        "      # 주어진 확률(점수)값에서 최대값을 선택하기\n",
        "      decode_idx =  output.argmax(2).detach().cpu()\n",
        "      result = torch.cat((result, decode_idx), dim=0)\n",
        "  \n",
        "      # loss 계산을 위한 조정\n",
        "      # output : (batch_size * seq_len, toekn_size)\n",
        "      token_size = output.size(-1)\n",
        "      output = output.view(-1, token_size)\n",
        "\n",
        "      # 위와 동일한 방식으로 label 값도 조정\n",
        "      # dec_target: (batch_size, seq_len)\n",
        "      # target (batch_size*seq_len,)\n",
        "      target = dec_target.view(-1)\n",
        "\n",
        "      loss = cri(output, target)\n",
        "      loss_ep += loss.item()\n",
        "  return loss_ep/len(loader), result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "9m6F7hknAqtm"
      },
      "outputs": [],
      "source": [
        "# 아래의 dictionary는 정수 인코딩 값을 넣으면 해당하는 원래 알파벳이 나옴\n",
        "# padding에 사용한 0도 decode해줘야 하고 이 때 ''으로 decode해주기\n",
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())\n",
        "index_to_tar[0] = ''\n",
        "index_to_src[0] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "F9c8z_7BAncv"
      },
      "outputs": [],
      "source": [
        "def decode(model, sample):\n",
        "  enc_input, dec_input, dec_output = sample\n",
        "  enc_input = enc_input.unsqueeze(0)\n",
        "  dec_input = dec_input.unsqueeze(0)\n",
        "  \n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    output = model(enc_input.to(device), dec_input.to(device), use_teacher_force=False)\n",
        "    decode_idx = output.argmax(2)\n",
        "\n",
        "  sentence_inp = pd.Series(enc_input.squeeze(0).detach().cpu().numpy()).apply(lambda x: index_to_src[x])\n",
        "  sentence_out = pd.Series(decode_idx.squeeze(0).detach().cpu().numpy()).apply(lambda x: index_to_tar[x])\n",
        "  sentence_act = pd.Series(dec_output.detach().cpu().numpy()).apply(lambda x: index_to_tar[x])\n",
        "\n",
        "  print(f\"입력 문장 : {' '.join(sentence_inp.tolist())}\")\n",
        "  print(f\"실제 문장 : {' '.join(sentence_act.tolist())}\")\n",
        "  print(f\"예측 문장 : {' '.join(sentence_out.tolist())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "9lARsr3wSyX8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIuESkCQSsSm",
        "outputId": "60cefc17-8386-493e-d919-6948fd024571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [02:10<19:34, 130.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0\n",
            "Train Loss : 8.3347\n",
            "Val Loss : 8.5424\n",
            "입력 문장 : 안녕하다 저희 한국 있다 저희 회사 새 사무실 위 인테리어 디자이너 찾다 있다 <EOS>\n",
            "실제 문장 : Good afternoon I m looking for an interior designer for my company s new South Korean offices <EOS>\n",
            "예측 문장 :  s AAA s AAA s AAA s AAA s AAA s AAA s AAA s AAA s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [06:22<14:50, 127.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2\n",
            "Train Loss : 7.1110\n",
            "Val Loss : 7.6192\n",
            "입력 문장 : 안녕하다 저희 한국 있다 저희 회사 새 사무실 위 인테리어 디자이너 찾다 있다 <EOS>\n",
            "실제 문장 : Good afternoon I m looking for an interior designer for my company s new South Korean offices <EOS>\n",
            "예측 문장 :  s  have  have  have  have  have  have  have  have\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [10:32<10:28, 125.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 4\n",
            "Train Loss : 5.4477\n",
            "Val Loss : 6.9792\n",
            "입력 문장 : 안녕하다 저희 한국 있다 저희 회사 새 사무실 위 인테리어 디자이너 찾다 있다 <EOS>\n",
            "실제 문장 : Good afternoon I m looking for an interior designer for my company s new South Korean offices <EOS>\n",
            "예측 문장 :  the the the              \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [14:41<06:15, 125.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 6\n",
            "Train Loss : 3.6438\n",
            "Val Loss : 7.0256\n",
            "입력 문장 : 안녕하다 저희 한국 있다 저희 회사 새 사무실 위 인테리어 디자이너 찾다 있다 <EOS>\n",
            "실제 문장 : Good afternoon I m looking for an interior designer for my company s new South Korean offices <EOS>\n",
            "예측 문장 :  you you you              \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [18:52<02:05, 125.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 8\n",
            "Train Loss : 2.5996\n",
            "Val Loss : 7.3457\n",
            "입력 문장 : 안녕하다 저희 한국 있다 저희 회사 새 사무실 위 인테리어 디자이너 찾다 있다 <EOS>\n",
            "실제 문장 : Good afternoon I m looking for an interior designer for my company s new South Korean offices <EOS>\n",
            "예측 문장 :                  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [21:01<00:00, 126.12s/it]\n"
          ]
        }
      ],
      "source": [
        "# 학습은 아래의 코드를 이용하여 진행\n",
        "\n",
        "train_lodaer = DataLoader(train_dataset, batch_size=1024)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "epochs = 10\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss_ep = train(model,train_lodaer,optimizer, criterion)\n",
        "  val_loss_ep, val_token = val(model, val_loader, criterion)\n",
        "\n",
        "  train_loss.append(train_loss_ep)\n",
        "  val_loss.append(val_loss_ep)\n",
        "  if epoch % 2 == 0:\n",
        "    print(f\"Epoch : {epoch}\")\n",
        "    print(f\"Train Loss : {train_loss_ep:.4f}\")\n",
        "    print(f\"Val Loss : {val_loss_ep:.4f}\")\n",
        "    decode(model, val_dataset[100])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "~아니 세상에 한영번역이었다니\n",
        "처음부터 다시 하겠습니다...~  \n",
        "완료하였습니다!! 그런데 예측은 잘 하지 못하고 있음  \n",
        "train loss는 계속하여 줄어들고 있는 것에 반하여, val loss는 5회의 epoch 이후 늘어나고 있는 것을 확인할 수 있다.  \n",
        "또한 예측하는 문장을 봐도 잘 예측하지 못하고 있음을 확인할 수 있다."
      ],
      "metadata": {
        "id": "nm-h8thBpoJX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Yaj3MORtbsNi"
      },
      "outputs": [],
      "source": [
        "# 학습을 진행한 다음, 모델 백업해놓기\n",
        "torch.save(model.state_dict(), 'model_hw.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}